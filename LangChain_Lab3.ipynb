{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdehghani86/AppliedGenAI/blob/main/LangChain_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5208c400",
      "metadata": {
        "id": "5208c400"
      },
      "source": [
        "# 🔗 **LangChain Lab 3: Chains & Agents**  \n",
        "- **Prof. Dehghani (m.dehghani@northeastern.edu)**  \n",
        "\n",
        "## **Lab Overview**  \n",
        "This lab focuses on **automating multi-step reasoning** and **decision-making** in LangChain using **Chains & Agents**.  \n",
        "You'll learn how to connect multiple components, dynamically execute logic, and use **LLMs to make decisions**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **🎯 What You'll Learn in This Lab**  \n",
        "In this session, you'll explore:  \n",
        "- 🔹 **Chains in LangChain** → How to connect multiple LLM calls in a sequence.  \n",
        "- 🔹 **Agents & Tools** → How to create AI-driven agents that reason & act dynamically.  \n",
        "- 🔹 **Hands-on exercises** → Reinforce concepts with practical coding tasks.  \n",
        "\n",
        "By the end of this lab, you’ll be able to **build AI workflows** that use **structured pipelines** and **autonomous decision-making** with LangChain! 🚀  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f1adbd",
      "metadata": {
        "id": "e0f1adbd"
      },
      "outputs": [],
      "source": [
        "# ==================================================\n",
        "# 📌 Installing Required Libraries\n",
        "# ==================================================\n",
        "!pip install langchain  # Core framework for working with LLMs\n",
        "!pip install langchain-community  # Install the community package containing LLMs\n",
        "!pip install openai==0.28  # OpenAI API package (version 0.28) for GPT models\n",
        "!pip install langchain-huggingface  # Hugging Face LLM wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f6983d2",
      "metadata": {
        "id": "9f6983d2"
      },
      "outputs": [],
      "source": [
        "# ==================================================\n",
        "# 📌 Importing Required Libraries for LangChain Lab\n",
        "# ==================================================\n",
        "\n",
        "# ✅ System & Environment Setup\n",
        "import os  # For setting environment variables, such as API keys\n",
        "\n",
        "# ✅ Jupyter & Colab Utilities\n",
        "import ipywidgets as widgets  # For creating interactive input widgets\n",
        "from IPython.display import clear_output, display  # For managing notebook outputs\n",
        "\n",
        "# ✅ OpenAI API\n",
        "import openai  # Direct interaction with OpenAI API (useful for API-based calls)\n",
        "\n",
        "# ✅ LangChain Components\n",
        "from langchain.llms import OpenAI  # Wrapper for interacting with OpenAI LLMs\n",
        "from langchain.chat_models import ChatOpenAI  # For chat-based OpenAI models\n",
        "from langchain.agents import AgentType, initialize_agent  # For creating AI agents\n",
        "from langchain.tools import Tool  # For adding external tools to agents\n",
        "from langchain.memory import ConversationBufferMemory  # For maintaining conversation history\n",
        "from langchain.prompts import PromptTemplate  # For creating structured prompts\n",
        "\n",
        "# ✅ Hugging Face Transformers (Only required if using Hugging Face models)\n",
        "import transformers  # Hugging Face library for pre-trained models\n",
        "\n",
        "# ✅ Confirmation message\n",
        "print(\"✅ All required libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4e47a7",
      "metadata": {
        "id": "2d4e47a7"
      },
      "outputs": [],
      "source": [
        "# ==================================================\n",
        "# 🔑 OpenAI API Key Setup with Output Clearing\n",
        "# ==================================================\n",
        "\n",
        "# ✅ Create input widget for the OpenAI API key\n",
        "openai_key_input = widgets.Password(\n",
        "    description=\"🔑 OpenAI Key:\",\n",
        "    placeholder=\"Enter your OpenAI API Key\",\n",
        ")\n",
        "\n",
        "# ✅ Create a button to submit the API key\n",
        "submit_button = widgets.Button(description=\"✅ Set API Key\")\n",
        "\n",
        "# ✅ Function to save the OpenAI API key when the button is clicked\n",
        "def set_api_key(b):\n",
        "    # Clear previous outputs\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Display the input field and button again\n",
        "    display(openai_key_input, submit_button)\n",
        "\n",
        "    # Retrieve and validate the OpenAI API key\n",
        "    openai_key = openai_key_input.value.strip()\n",
        "\n",
        "    # ✅ Set OpenAI API Key\n",
        "    if openai_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "        openai.api_key = openai_key\n",
        "        print(\"✅ OpenAI API Key has been set successfully!\")\n",
        "    else:\n",
        "        print(\"❌ Please enter a valid OpenAI API Key.\")\n",
        "\n",
        "# ✅ Link button click to the function\n",
        "submit_button.on_click(set_api_key)\n",
        "\n",
        "# ✅ Display the input field and button\n",
        "display(openai_key_input, submit_button)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔗 **Understanding Chains in LangChain**  \n",
        "\n",
        "One of the **core features** of LangChain is its ability to **create chains**, allowing us to **sequence multiple tasks together**.  \n",
        "Instead of manually handling each step, **chains automate workflows** by linking components such as **prompts, LLMs, memory, and tools**.  \n",
        "\n",
        "## ✅ Why Use Chains in LangChain?  \n",
        "🔹 **Automate multi-step processes** → No need to manually pass outputs between steps.  \n",
        "🔹 **Create structured AI pipelines** → Chain together **LLMs, retrievers, memory, and tools**.  \n",
        "🔹 **Enable decision-making AI agents** → Chains help **LLMs interact with external tools** to retrieve and process information dynamically.  \n",
        "\n",
        "## 🔗 **Using the Pipe (`|`) Operator for Cleaner Chaining**  \n",
        "LangChain provides a **simplified way** to create chains using the **pipe (`|`) operator**, which allows direct data flow between components.  \n",
        "\n",
        "### **🔍 Example: Two Ways to Process Input with an LLM**  \n",
        "\n",
        "🔹 **Without Pipe (`|`)** → Manually format the input, then pass it to the LLM.  \n",
        "🔹 **With Pipe (`|`)** → Directly chain them together for **automatic execution**.  \n",
        "\n",
        "Let's compare both approaches in the next code cells! 🚀  \n"
      ],
      "metadata": {
        "id": "F7lwDEVbbG1v"
      },
      "id": "F7lwDEVbbG1v"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 🔹 **Comparing Two Methods: Manual Execution vs. Pipe (`|`) Operator**\n",
        "# ==================================================\n",
        "# This example demonstrates two ways to process an input with an LLM:\n",
        "#\n",
        "# 1️⃣ **Without Pipe (`|`)** → Manually format the prompt and pass it to the LLM.\n",
        "# 2️⃣ **With Pipe (`|`)** → Use LangChain’s `|` operator to create a streamlined sequence.\n",
        "#\n",
        "# Using the `|` operator allows for **cleaner, automatic execution**, reducing code complexity.\n",
        "\n",
        "\n",
        "# ✅ Define a prompt template with a World Cup theme\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"event\"],\n",
        "    template=\"\"\"\n",
        "    You are a legendary sports analyst with deep knowledge of World Cup history.\n",
        "    Fans eagerly await your expert take on the most iconic moments.\n",
        "\n",
        "    Analyze this legendary World Cup event in max ~20 simple words: {event}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# ✅ Initialize the LLM (GPT-4)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
        "\n",
        "# ==================================================\n",
        "# ❌ Without Using the Pipe (`|`) - More Manual Steps\n",
        "# ==================================================\n",
        "# 1️⃣ Manually format the prompt\n",
        "formatted_prompt = prompt.format(event=\"Zidane's 2006 World Cup final red card\")\n",
        "\n",
        "# 2️⃣ Pass it to the LLM manually (Fixed: Removed unnecessary dictionary)\n",
        "response_without_pipe = llm.invoke(formatted_prompt)\n",
        "\n",
        "# ✅ Print the response\n",
        "print(\"❌ Without Pipe Response:\", response_without_pipe.content)\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Using the Pipe (`|`) - Cleaner and Automatic Execution\n",
        "# ==================================================\n",
        "# 1️⃣ Directly chain the prompt and LLM together\n",
        "chain = prompt | llm  # This creates a RunnableSequence\n",
        "\n",
        "# 2️⃣ Run the chain with an input in one step (Fixed: Using correct format)\n",
        "response_with_pipe = chain.invoke({\"event\": \"Zidane's 2006 World Cup final red card\"})\n",
        "\n",
        "# ✅ Print the response\n",
        "print(\"✅ With Pipe Response:\", response_with_pipe.content)\n"
      ],
      "metadata": {
        "id": "qboSX5pObOmo"
      },
      "id": "qboSX5pObOmo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✋ Hands-On: Single Prompt Chain"
      ],
      "metadata": {
        "id": "jS5bBlCKjE4H"
      },
      "id": "jS5bBlCKjE4H"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# ✋ **Hands-On 1: Creating a Single Prompt Chain**\n",
        "# ==================================================\n",
        "\n",
        "# 📌 **Task Instructions:**\n",
        "# 1️⃣ Fill in the missing placeholders (-----) to complete the code.\n",
        "# 2️⃣ Ensure the Prompt Template correctly replaces {topic}.\n",
        "# 3️⃣ Run the code and verify GPT-4 generates a response.\n",
        "\n",
        "# ✅ Step 1: Import necessary modules\n",
        "from langchain.prompts import -----  # Import the correct class\n",
        "from langchain.chat_models import -----  # Import the correct class\n",
        "\n",
        "# ✅ Step 2: Define a Prompt Template\n",
        "prompt_template = -----(\n",
        "    input_variables=[\"-----\"],  # Placeholder for dynamic input\n",
        "    template=\"Explain {topic} in simple terms using no more than 15 words.\"\n",
        ")\n",
        "\n",
        "# ✅ Step 3: Initialize GPT-4 model\n",
        "llm_ChatGPT = -----(model_name=\"gpt-4\")  # Load GPT-4 model\n",
        "\n",
        "# ✅ Step 4: Create a runnable chain using `|` (pipe operator)\n",
        "chain = prompt_template ----- llm_ChatGPT  # Use the correct operator to chain them\n",
        "\n",
        "# ✅ Step 5: Run the chain with a sample input\n",
        "response = chain.invoke({\"topic\": \"Collective Intelligence\"})\n",
        "\n",
        "# ✅ Step 6: Display results\n",
        "print(\"🔹 **Generated Prompt:**\", prompt_template.format(topic=\"Collective Intelligence\"))\n",
        "print(\"🔹 **LLM Response:**\", response.-----)  # Extract and display response content\n"
      ],
      "metadata": {
        "id": "3WLVBwwAi6Iu"
      },
      "id": "3WLVBwwAi6Iu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 Multi-LLM Pipelines with Chaining  \n",
        "\n",
        "## 🔹 What is Multi-LLM Chaining?  \n",
        "Multi-LLM chaining is a method where **multiple AI models** collaborate in a **step-by-step sequence** to handle complex tasks efficiently. Instead of a single model doing everything, **each AI is specialized** for a specific function, ensuring **better accuracy, efficiency, and interpretability**.  \n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Key Benefits of Multi-LLM Chaining**\n",
        "✔️ **Task Specialization** – Each model is optimized for a **specific role**, leading to **higher accuracy**.  \n",
        "✔️ **Improved Efficiency** – Models **focus on one task at a time**, reducing processing load and response time.  \n",
        "✔️ **Scalability** – Easily extendable by adding **more AI models** for deeper analysis.  \n",
        "✔️ **Transparency & Interpretability** – Step-by-step outputs **show AI reasoning**, making results easier to trust.  \n",
        "✔️ **Error Reduction** – If an early step **detects errors**, later models can **correct them** for a refined output.  \n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Real-World Applications of Multi-LLM Chaining\n",
        "🔹 **Legal AI:** One model extracts case details, another predicts legal outcomes.  \n",
        "🔹 **Customer Support:** One model classifies sentiment, another generates a response.  \n",
        "🔹 **Content Writing:** One model creates content, another summarizes or edits it.  \n",
        "🔹 **Fake News Detection:** One model extracts claims, another fact-checks them.  \n",
        "\n",
        "By chaining **specialized AI models**, we can **enhance AI reasoning**, improve accuracy, and build more **intelligent, structured workflows** across different industries. 🌟  \n",
        "\n",
        "---\n",
        "\n",
        "## 🏥 Example: Medical Diagnosis Chain  \n",
        "In a medical AI pipeline:  \n",
        "1️⃣ **GPT-4 Turbo** → Analyzes symptoms and suggests possible conditions.  \n",
        "2️⃣ **GPT-4-01** → Evaluates the list and selects the **most likely condition** with reasoning.  \n",
        "\n",
        "This structured approach **breaks down decision-making into logical steps**, leading to **more reliable outputs**.\n"
      ],
      "metadata": {
        "id": "wvyg7LSSgrVi"
      },
      "id": "wvyg7LSSgrVi"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 1: Define Two LLMs\n",
        "# ================================\n",
        "\n",
        "# 🔹 First LLM (GPT-4 Turbo) - Medical AI: Finds Possible Conditions\n",
        "llm_medical = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)\n",
        "\n",
        "# 🔹 Second LLM (GPT-4-01) - Reasoning AI: Selects Best Condition & Justifies\n",
        "llm_reasoning = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0.0)\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 2: Create Prompt Templates\n",
        "# ================================\n",
        "\n",
        "# 🔹 Prompt for Medical AI (Find Possible Conditions)\n",
        "prompt_medical = PromptTemplate(\n",
        "    input_variables=[\"symptoms\"],\n",
        "    template=\"\"\"\n",
        "    You are an AI medical assistant. Based on the symptoms provided, suggest up to 3 possible conditions.\n",
        "\n",
        "    Symptoms: {symptoms}\n",
        "\n",
        "    Respond in a **comma-separated list** (e.g., \"Flu, COVID-19, Pneumonia\").\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 🔹 Prompt for Reasoning AI (Pick the Most Likely Condition)\n",
        "prompt_reasoning = PromptTemplate(\n",
        "    input_variables=[\"conditions\"],\n",
        "    template=\"\"\"\n",
        "    You are an AI doctor. Based on the possible conditions listed, pick the **most probable** one and provide a **brief reason**.\n",
        "\n",
        "    Possible conditions: {conditions}\n",
        "\n",
        "    Respond with **only the best condition + reasoning in ≤15 words**.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 3: Create the Chain (Using `|` Operator)\n",
        "# ================================\n",
        "\n",
        "# 🔹 Chain Explanation:\n",
        "# 1️⃣ GPT-4 Turbo gets symptoms → outputs possible conditions\n",
        "# 2️⃣ The conditions are passed automatically to GPT-4-01\n",
        "# 3️⃣ GPT-4-01 picks **one most likely condition** & gives a short reason\n",
        "\n",
        "medical_chain = (\n",
        "    prompt_medical  # Step 1: Format symptoms into a medical prompt\n",
        "    | llm_medical   # Step 2: Use GPT-4 Turbo to find possible conditions\n",
        "    | (lambda x: {\"conditions\": x.content})  # Step 3: Extract conditions as input for next LLM\n",
        "    | prompt_reasoning  # Step 4: Format the conditions for reasoning AI\n",
        "    | llm_reasoning  # Step 5: Use GPT-4-01 to pick the best condition\n",
        ")"
      ],
      "metadata": {
        "id": "iIMmsdZFgxXZ"
      },
      "id": "iIMmsdZFgxXZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Test Case 1: Common Cold Symptoms\n",
        "symptoms_input = \"runny nose, sneezing, mild headache\"\n",
        "\n",
        "response = medical_chain.invoke({\"symptoms\": symptoms_input})\n",
        "\n",
        "print(\"🔍 Possible Conditions (GPT-4 Turbo):\", response.content)\n"
      ],
      "metadata": {
        "id": "MCeLejCTMqOz"
      },
      "id": "MCeLejCTMqOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Test Case 2: Severe Flu-like Symptoms\n",
        "symptoms_input = \"fever, chills, muscle pain, fatigue\"\n",
        "\n",
        "response = medical_chain.invoke({\"symptoms\": symptoms_input})\n",
        "\n",
        "print(\"🔍 Possible Conditions (GPT-4 Turbo):\", response.content)\n"
      ],
      "metadata": {
        "id": "sip86GtOMwdE"
      },
      "id": "sip86GtOMwdE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Test Case 3: Stomach-related Symptoms\n",
        "symptoms_input = \"nausea, vomiting, diarrhea, stomach cramps\"\n",
        "\n",
        "response = medical_chain.invoke({\"symptoms\": symptoms_input})\n",
        "\n",
        "print(\"🔍 Possible Conditions (GPT-4 Turbo):\", response.content)\n"
      ],
      "metadata": {
        "id": "wzJu_UAgMyyC"
      },
      "id": "wzJu_UAgMyyC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✋ Hands-On Exercise: Customer Review Analysis & Automated Response"
      ],
      "metadata": {
        "id": "dMppSO10jOgf"
      },
      "id": "dMppSO10jOgf"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# ✋ **Hands-On: Customer Review Sentiment & AI Response**\n",
        "# ==================================================\n",
        "# 📌 **Task Instructions:**\n",
        "# 1️⃣ Fill in the missing placeholders (`-----`) to complete the code.\n",
        "# 2️⃣ Ensure both Prompt Templates correctly embed {review} and {sentiment}.\n",
        "# 3️⃣ Run the code and verify the AI-generated sentiment & response.\n",
        "\n",
        "# ✅ Step 1: Import necessary modules\n",
        "\n",
        "# ✅ Step 2: Initialize two different LLMs\n",
        "llm_sentiment = -----(\"gpt-4-turbo\")  # GPT-4 Turbo for sentiment analysis\n",
        "llm_response = -----(\"gpt-4-1106-preview\")  # GPT-4-01 for response generation\n",
        "\n",
        "# ✅ Step 3: Define the first Prompt Template (Sentiment Analysis)\n",
        "sentiment_prompt = -----(\n",
        "    input_variables=[\"-----\"],  # Define the input variable for review input\n",
        "    template=\"\"\"\n",
        "    You are an AI assistant analyzing customer sentiment.\n",
        "\n",
        "    Review: {review}\n",
        "\n",
        "    Respond with either \"Positive\", \"Neutral\", or \"Negative\".\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# ✅ Step 4: Define the second Prompt Template (Automated Response)\n",
        "response_prompt = -----(\n",
        "    input_variables=[\"-----\"],  # Define the input variable for sentiment classification\n",
        "    template=\"\"\"\n",
        "    You are an AI customer support agent. Based on the sentiment, generate a short, polite response.\n",
        "\n",
        "    Sentiment: {sentiment}\n",
        "\n",
        "    Response (≤ 15 words):\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# ✅ Step 5: Create Runnable Chains using the `|` operator\n",
        "sentiment_chain = ----- | -----  # Chain the sentiment prompt with GPT-4 Turbo\n",
        "response_chain = ----- | -----  # Chain the response prompt with GPT-4-01\n",
        "\n",
        "# ✅ Step 6: Run the pipeline\n",
        "\n",
        "# Step 6.1: Sample customer review input\n",
        "customer_review = \"The product is amazing! Great quality and fast delivery. Will buy again.\"\n",
        "\n",
        "# Step 6.2: Analyze sentiment using GPT-4 Turbo\n",
        "sentiment_result = sentiment_chain.-----({\"review\": customer_review})  # Call the function to invoke the model\n",
        "\n",
        "# Step 6.3: Generate AI response using GPT-4-01\n",
        "response_text = response_chain.-----({\"sentiment\": sentiment_result.-----})  # Ensure correct content extraction\n",
        "\n",
        "# ✅ Step 7: Display results\n",
        "print(\"🔍 **Detected Sentiment:**\", sentiment_result.-----)  # Extract response content\n",
        "print(\"\\n💬 **AI Response:**\", response_text.-----)  # Extract AI-generated response\n",
        "\n",
        "\n",
        "#+++++++ Example Output +++++++#\n",
        "#🔍 **Detected Sentiment:** Positive\n",
        "#💬 **AI Response:** Thank you for your kind words! We’re glad you loved it! 😊\n"
      ],
      "metadata": {
        "id": "WV19WC9ujSna"
      },
      "id": "WV19WC9ujSna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✋ Hands-On Exercise: Customer Review Analysis & Automated Response (Merged Chain)"
      ],
      "metadata": {
        "id": "szagChUdO841"
      },
      "id": "szagChUdO841"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# ✋ **Hands-On: Merged Chain for Customer Review Sentiment & AI Response**\n",
        "# ==================================================\n",
        "# 📌 **Task Instructions:**\n",
        "# 1️⃣ Fill in the missing placeholders (`-----`) to complete the chain.\n",
        "# 2️⃣ Ensure sentiment analysis flows correctly into the response generation.\n",
        "# 3️⃣ Run the code and verify AI-generated responses.\n",
        "\n",
        "# ✅ The `PromptTemplate` and LLMs (`llm_sentiment` and `llm_response`) are already defined.\n",
        "\n",
        "# ✅ Step 5: Create a Single Runnable Chain (Merged Approach)\n",
        "full_chain = (\n",
        "    -----  # Step 1: Start with the sentiment prompt\n",
        "    | -----  # Step 2: Pass it to the sentiment analysis LLM\n",
        "    | (lambda x: {\"sentiment\": x.content})  # Step 3: Extract sentiment result\n",
        "    | -----  # Step 4: Format sentiment into response prompt\n",
        "    | -----  # Step 5: Pass it to the response generation LLM\n",
        ")\n",
        "\n",
        "# ✅ Step 6: Run the pipeline\n",
        "\n",
        "# Sample customer review input\n",
        "customer_review = \"The product is amazing! Great quality and fast delivery. Will buy again.\"\n",
        "\n",
        "# Run the full pipeline in one step\n",
        "response = full_chain.invoke({\"review\": customer_review})\n",
        "\n",
        "# ✅ Step 7: Display results\n",
        "print(\"💬 **AI Response:**\", response.content)  # Extract AI-generated response\n"
      ],
      "metadata": {
        "id": "RwRSZ76pO5JH"
      },
      "id": "RwRSZ76pO5JH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 AI Agents: Beyond Basic LLM Chaining  \n",
        "\n",
        "## 🔹 What are AI Agents?  \n",
        "Unlike simple LLM pipelines where models work in a **fixed sequence**, **AI agents** are **more flexible** and can **make decisions dynamically**. They can interact with **external tools, APIs, memory, and reasoning frameworks** to **adapt their responses** based on the situation.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 **LLM Chaining vs. AI Agents**\n",
        "| Feature           | LLM Chaining                     | AI Agents                      |\n",
        "|------------------|--------------------------------|--------------------------------|\n",
        "| **Execution**    | Fixed sequence of steps        | Dynamic, adaptive behavior    |\n",
        "| **Decision-Making** | Follows predefined logic       | Can reason and choose actions |\n",
        "| **Interactivity** | Limited to internal logic      | Can use APIs, databases, tools |\n",
        "| **Memory**       | No long-term state             | Can remember previous actions |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Why Use AI Agents?**\n",
        "✔️ **Decision-Making** – Agents **select actions** dynamically instead of just following a script.  \n",
        "✔️ **Tool Integration** – Can access **APIs, databases, and external tools** like search engines or calculators.  \n",
        "✔️ **Memory** – Stores past interactions to **improve responses over time**.  \n",
        "✔️ **Multi-Step Reasoning** – Can **plan**, execute, and refine responses based on feedback.  \n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Real-World Applications of AI Agents\n",
        "🔹 **Customer Support AI:** Detects user needs, queries databases, and provides **real-time support**.  \n",
        "🔹 **Financial AI:** Analyzes market trends, retrieves **live stock prices**, and recommends investments.  \n",
        "🔹 **Research Assistants:** Searches the web, **extracts insights**, and summarizes articles.  \n",
        "🔹 **Automated Workflow Agents:** Interact with **multiple APIs** to execute complex business tasks.  \n",
        "\n",
        "---\n",
        "\n",
        "## ⚡ Next Steps: Building an AI Agent  \n",
        "Now, let’s **create an AI agent** that can **reason, interact with tools, and make decisions** dynamically! 🚀  \n"
      ],
      "metadata": {
        "id": "sYopzX5PSmNR"
      },
      "id": "sYopzX5PSmNR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧮 Lab: Building a Math Solver Agent  \n",
        "\n",
        "In this lab, we create an **AI agent** that can solve **math problems dynamically** using a **calculator tool**. The agent **decides** whether to perform calculations itself or use external tools, showcasing **reasoning and tool integration** in LangChain.  \n",
        "\n",
        "The agent is executed using **`.run()`**, which allows it to process user queries and decide on actions dynamically.  \n",
        "\n",
        "---\n",
        "\n",
        "## 🔹 What is a Tool in LangChain?  \n",
        "A **tool** in LangChain is an **external function** that an agent can call to perform **specialized tasks** beyond just text generation. Tools help **extend AI capabilities**, allowing it to:  \n",
        "✔️ **Perform calculations** (e.g., a calculator tool)  \n",
        "✔️ **Query APIs** (e.g., fetch stock prices, weather updates)  \n",
        "✔️ **Search databases** (e.g., retrieve company records)  \n",
        "\n",
        "In this lab, we use a **calculator tool** to enable precise **math computation**, ensuring accurate results instead of relying solely on an LLM’s reasoning.  "
      ],
      "metadata": {
        "id": "s-JOOTTym4Iu"
      },
      "id": "s-JOOTTym4Iu"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 🏗️ Build the Math Solver Agent\n",
        "# ================================\n",
        "# ✅ This cell initializes the agent with a reasoning LLM and a calculator tool.\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI  # This imports the OpenAI-powered chatbot model for conversational AI\n",
        "from langchain.agents import initialize_agent, AgentType  # This is used to initialize an agent with a specific type\n",
        "from langchain.tools import Tool  # Tool class is used to define custom tools that the agent can use\n",
        "import operator  # Importing the operator module to perform mathematical and logical operations\n",
        "\n",
        "# ✅ Step 1: Define the LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)\n",
        "\n",
        "import operator  # Importing the operator module for mathematical operations\n",
        "\n",
        "# ✅ Step 2: Create a Calculator Tool\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Securely evaluates a mathematical expression and returns the computed result.\n",
        "\n",
        "    This function allows basic arithmetic operations while restricting access to\n",
        "    potentially dangerous built-in functions.\n",
        "\n",
        "    Supported operations:Addition (+), Subtraction (-), Multiplication (*)\n",
        "    - Division (/), Exponentiation (**), Floor Division (//), Modulus (%)\n",
        "\n",
        "    Parameters:\n",
        "    expression (str): A valid mathematical expression in string format\n",
        "                      (e.g., \"5 + 3\", \"10 * 2\", \"8 ** 2\").\n",
        "\n",
        "    Returns:\n",
        "    str: The computed result as a string, or an error message if the input is invalid.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ✅ Securely evaluate the mathematical expression\n",
        "        # - `eval()` computes the arithmetic operation safely.\n",
        "        # - `{\"__builtins__\": {}}` removes access to all built-in functions, preventing security risks.\n",
        "        # - `operator.__dict__` limits the allowed operations to those defined in the operator module.\n",
        "        result = eval(expression, {\"__builtins__\": {}}, operator.__dict__)\n",
        "\n",
        "        # ✅ Convert the result to a string before returning it\n",
        "        return str(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        # ✅ Handle errors gracefully, such as:\n",
        "        # - Invalid mathematical expressions (e.g., \"five plus three\" instead of \"5 + 3\")\n",
        "        # - Unsupported operations\n",
        "        # - Division by zero\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "calculator = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=calculator_tool,\n",
        "    description=\"Use this tool to perform basic arithmetic calculations.\"\n",
        ")\n",
        "\n",
        "# ✅ Step 3: Initialize the Math Solver Agent\n",
        "math_solver_agent = initialize_agent(\n",
        "    tools=[calculator],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "hlWQ9rtoSnLc"
      },
      "id": "hlWQ9rtoSnLc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔹 Why Do We Need an LLM for the Math Solver Agent?  \n",
        "\n",
        "The **LLM (GPT-4 Turbo)** is essential for enabling **natural language understanding and reasoning** in the **Math Solver Agent**.  \n",
        "\n",
        "### **✅ Why Keep the LLM?**  \n",
        "✔ Interprets **human-like queries** (e.g., `\"Multiply 10 by 3\"` → `\"10 * 3\"`)  \n",
        "✔ Decides **when to use the calculator tool**  \n",
        "✔ Provides **error handling and explanations** in natural language  \n",
        "✔ Responds to **unsupported queries** instead of failing  \n",
        "\n",
        "### **❌ What Happens Without It?**  \n",
        "🔹 Only strict expressions (e.g., `\"5 + 3\"`) work, no **language understanding**  \n",
        "🔹 The tool **cannot reason** or decide how to handle a query  \n",
        "🔹 The agent **becomes a basic calculator**, losing flexibility  \n",
        "\n",
        "🚀Using the LLM makes the agent **more intelligent, flexible, and user-friendly** beyond just executing math operations.  \n"
      ],
      "metadata": {
        "id": "gaySwvBeiTlY"
      },
      "id": "gaySwvBeiTlY"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 🧪 Test the Math Solver Agent\n",
        "# ================================\n",
        "# ✅ This cell runs the agent with different math problems.\n",
        "\n",
        "# 🔹 Test Cases (Increasing Difficulty):\n",
        "test_cases = [\n",
        "    \"What is 42 * (8 + 3)?\",  # Simple arithmetic\n",
        "    \"Solve for x: 3x + 5 = 20.\",  # Equation solving\n",
        "    \"Integrate (3x^2 + 2x - 5) dx.\",  # Advanced calculus (integration)\n",
        "]\n",
        "\n",
        "# 🔹 Run the agent on each test case one by one\n",
        "for query in test_cases:\n",
        "    response = math_solver_agent.run(query)\n",
        "    print(f\"🧮 Query: {query}\")\n",
        "    print(f\"📢 Response: {response}\\n\")\n"
      ],
      "metadata": {
        "id": "hOe8c9LemiCs"
      },
      "id": "hOe8c9LemiCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💡 Did You Realize? Your Agent is Smarter Than You Think!\n",
        "\n",
        "### ❓ Why does the Math Solver Agent understand `\"Multiply 10 by 3\"` even though there is no prompt?  \n",
        "✅ The agent uses **`ZERO_SHOT_REACT_DESCRIPTION`**, which **automatically prompts the LLM** behind the scenes.  \n",
        "\n",
        "### ❓ How does the LLM convert `\"Multiply 10 by 3\"` into `\"10 * 3\"`?  \n",
        "✅ LangChain **asks the LLM to interpret the query** and map words to mathematical symbols before calling the calculator tool.  \n",
        "\n",
        "### ❓ What happens if we remove the LLM?  \n",
        "✅ The agent **won’t understand** `\"Multiply 10 by 3\"`, and only exact expressions like `\"10 * 3\"` will work.  \n",
        "\n",
        "### ❓ Does the definition of a tool get passed to the LLM?  \n",
        "✅ Yes! The agent **passes the tool’s description** to the LLM so it knows when and how to use it.  \n",
        "\n",
        "### ❓ Can an agent have multiple tools?  \n",
        "✅ Yes! An agent can use **multiple tools**, and the LLM will decide which one to call based on the query."
      ],
      "metadata": {
        "id": "UXqFE7nxjjlY"
      },
      "id": "UXqFE7nxjjlY"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ✋ Hands-On: Build a Unit Conversion Agent\n",
        "# ================================\n",
        "# 📌 **Task Instructions:**\n",
        "# 1️⃣ Fill in the missing placeholders (`-----`) to complete the code.\n",
        "# 2️⃣ Ensure the tool and agent are correctly initialized.\n",
        "# 3️⃣ Test the agent by providing a conversion query.\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI  # Importing OpenAI-powered LLM\n",
        "from langchain.agents import initialize_agent, AgentType  # For agent initialization\n",
        "from langchain.tools import Tool  # Tool class to define custom tools for the agent\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 1: Define the LLM\n",
        "# ================================\n",
        "# 🔹 Fill in the placeholder to define the LLM\n",
        "llm = -----(\"gpt-4-turbo\", temperature=0.0)\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 2: Create a Unit Conversion Tool\n",
        "# ================================\n",
        "def unit_conversion_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Handles unit conversions for basic metrics like length, weight, and temperature.\n",
        "\n",
        "    Supported conversions:\n",
        "    - Miles to Kilometers\n",
        "    - Kilograms to Pounds\n",
        "    - Celsius to Fahrenheit\n",
        "\n",
        "    The function extracts the numerical value from the query string, performs the\n",
        "    specified conversion, and returns the result as a formatted string.\n",
        "\n",
        "    Returns:\n",
        "    str: The conversion result or an error message if the query is unsupported or invalid.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if \"miles to kilometers\" in query.lower():\n",
        "            miles = float(query.split()[0])\n",
        "            return f\"{miles} miles is {miles * 1.60934:.2f} kilometers.\"\n",
        "        elif \"kilograms to pounds\" in query.lower():\n",
        "            kg = float(query.split()[0])\n",
        "            return f\"{kg} kilograms is {kg * 2.20462:.2f} pounds.\"\n",
        "        elif \"celsius to fahrenheit\" in query.lower():\n",
        "            celsius = float(query.split()[0])\n",
        "            return f\"{celsius}°C is {celsius * 9/5 + 32:.2f}°F.\"\n",
        "        else:\n",
        "            return (\n",
        "                \"Unsupported conversion. Supported conversions:\\n\"\n",
        "                \"- Miles to Kilometers\\n\"\n",
        "                \"- Kilograms to Pounds\\n\"\n",
        "                \"- Celsius to Fahrenheit\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        return f\"Error: Unable to process the query. Details: {str(e)}\"\n",
        "\n",
        "\n",
        "# 🔹 Fill in the placeholder to define the tool\n",
        "unit_converter = Tool(\n",
        "    name=\"Unit Converter\",\n",
        "    func=-----,  # Function to handle unit conversions\n",
        "    description=\"Use this tool to convert units like miles to kilometers, kilograms to pounds, and Celsius to Fahrenheit.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 3: Initialize the Unit Conversion Agent\n",
        "# ================================\n",
        "# 🔹 Fill in the placeholder to initialize the agent\n",
        "unit_conversion_agent = initialize_agent(\n",
        "    tools=[-----],  # Tool for unit conversion\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 4: Test the Unit Conversion Agent\n",
        "# ================================\n",
        "# 🔹 Example query for conversion\n",
        "query = \"5 miles to kilometers\"\n",
        "\n",
        "# 🔹 Run the agent with the query\n",
        "response = unit_conversion_agent.run(query)\n",
        "\n",
        "# 🔹 Print the response\n",
        "print(\"🔄 Unit Conversion Agent Response:\\n\", response)\n"
      ],
      "metadata": {
        "id": "P_YFRx0LxisN"
      },
      "id": "P_YFRx0LxisN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📈 Stock Market Agent with Simplified Analytics\n",
        "\n",
        "This lab demonstrates how to create a **Stock Market Agent** that retrieves and analyzes AAPL stock data. The agent calculates the **latest close price**, **price changes**, and determines the **trend direction** (upwards or downwards) using historical data. By leveraging LangChain tools and an LLM, the agent provides concise and actionable insights into stock performance.\n"
      ],
      "metadata": {
        "id": "BaXtG9OwxsTp"
      },
      "id": "BaXtG9OwxsTp"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 📈 Stock Market Agent with Simplified Analytics\n",
        "# ================================\n",
        "# ✅ This agent retrieves the latest AAPL stock data and provides concise analytics.\n",
        "\n",
        "import pandas as pd  # For handling CSV data\n",
        "from langchain.chat_models import ChatOpenAI  # LLM for reasoning and insights\n",
        "from langchain.agents import initialize_agent, AgentType  # Agent framework\n",
        "from langchain.tools import Tool  # Tool integration\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 1: Load AAPL Stock Data from Dropbox\n",
        "# ================================\n",
        "# 🔹 Load the historical stock data\n",
        "csv_url = \"https://www.dropbox.com/scl/fi/ysqxvj39gx2bkl4husg3y/HistoricalData_1739205046441.csv?rlkey=36q4rjpvvmwt9fyf3fftxwvb3&dl=1\"\n",
        "stock_data = pd.read_csv(csv_url)\n",
        "\n",
        "# 🔹 Format the \"Close/Last\" column (remove \"$\" sign and convert to float)\n",
        "stock_data['Close/Last'] = stock_data['Close/Last'].str.replace('$', '').astype(float)\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 2: Define the Stock Analytics Tool\n",
        "# ================================\n",
        "def get_aapl_analytics(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches the latest stock data and provides simplified analytics:\n",
        "    - Latest close price\n",
        "    - Percentage price change compared to the previous day\n",
        "    - Trend direction (upward/downward)\n",
        "    \"\"\"\n",
        "    # Get the latest and previous stock data\n",
        "    latest_entry = stock_data.iloc[-1]  # Most recent row\n",
        "    previous_entry = stock_data.iloc[-2]  # Second last row\n",
        "\n",
        "    # Calculate price change and percentage change\n",
        "    price_change = latest_entry['Close/Last'] - previous_entry['Close/Last']\n",
        "    price_change_percent = (price_change / previous_entry['Close/Last']) * 100\n",
        "\n",
        "    # Determine the trend direction\n",
        "    trend = \"upwards 📈\" if price_change > 0 else \"downwards 📉\"\n",
        "\n",
        "    # Create a simplified response\n",
        "    response = (\n",
        "        f\"📅 Date: {latest_entry['Date']}\\n\"\n",
        "        f\"🔹 Close Price: ${latest_entry['Close/Last']}\\n\"\n",
        "        f\"🔹 Price Change: {price_change:.2f} ({price_change_percent:.2f}%)\\n\"\n",
        "        f\"🔹 Trend: The stock is trending {trend}.\\n\"\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# 🔹 Register the analytics tool\n",
        "analytics_tool = Tool(\n",
        "    name=\"AAPL Stock Analytics\",\n",
        "    func=get_aapl_analytics,\n",
        "    description=\"Provides analytics for AAPL stock, including close price, price changes, and trend direction.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 3: Initialize the Stock Market Agent\n",
        "# ================================\n",
        "# 🔹 Initialize the GPT-4 Turbo model for reasoning\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)\n",
        "\n",
        "# 🔹 Setup the agent with the analytics tool\n",
        "stock_agent = initialize_agent(\n",
        "    tools=[analytics_tool],  # The agent uses the analytics tool to fetch and analyze data\n",
        "    llm=llm,  # LLM for reasoning and generating insights\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # A simple reactive agent\n",
        "    verbose=True  # Display detailed logs for better understanding\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 4: Run the Stock Market Agent\n",
        "# ================================\n",
        "# 🔹 Example query to analyze AAPL stock\n",
        "query = \"Provide the latest stock data for AAPL.\"\n",
        "\n",
        "# 🔹 Get the agent's response\n",
        "response = stock_agent.run(query)\n",
        "\n",
        "# 🔹 Print the response\n",
        "print(\"📊 Stock Market Agent Response:\\n\", response)\n"
      ],
      "metadata": {
        "id": "-VXDJT4zoSSD"
      },
      "id": "-VXDJT4zoSSD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 📈 Chaining Analytics and Graphing Agents\n",
        "# ================================\n",
        "# ✅ This cell demonstrates chaining two agents: one for analytics and another for graphing.\n",
        "\n",
        "import matplotlib.pyplot as plt  # For graphing stock price trends\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 1: Define the Graphing Tool\n",
        "# ================================\n",
        "def generate_stock_graph(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a stock price trend graph for AAPL over the last 10 days.\n",
        "    \"\"\"\n",
        "    # Extract the last 10 days of data\n",
        "    recent_data = stock_data.tail(10)\n",
        "    dates = recent_data['Date']\n",
        "    close_prices = recent_data['Close/Last']\n",
        "\n",
        "    # Create the graph\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(dates, close_prices, marker='o', linestyle='-', color='blue')\n",
        "    plt.title(\"AAPL Stock Price Trend (Last 10 Days)\", fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"Close Price ($)\", fontsize=12)\n",
        "    plt.xticks(rotation=45, fontsize=10)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"aapl_stock_trend.png\")  # Save the graph as an image\n",
        "    plt.close()\n",
        "\n",
        "    return \"📊 Stock trend graph generated successfully: 'aapl_stock_trend.png'\"\n",
        "\n",
        "# 🔹 Register the graphing tool\n",
        "graph_tool = Tool(\n",
        "    name=\"Graph Generator\",\n",
        "    func=generate_stock_graph,\n",
        "    description=\"Generates a graph of AAPL's stock price trend over the last 10 days.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 2: Chain the Agents\n",
        "# ================================\n",
        "\n",
        "# 🔹 Analytics Agent (from previous step)\n",
        "analytics_agent = stock_agent  # This uses the existing analytics agent\n",
        "\n",
        "# 🔹 Graphing Agent\n",
        "llm_graph = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)\n",
        "graphing_agent = initialize_agent(\n",
        "    tools=[graph_tool],  # The graphing tool generates the stock graph\n",
        "    llm=llm_graph,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 🔹 Chain Execution: Run analytics first, then graphing\n",
        "query = \"Provide the latest stock data for AAPL.\"\n",
        "\n",
        "# Step 1: Run the analytics agent\n",
        "analytics_response = analytics_agent.run(query)\n",
        "print(\"📈 Analytics Agent Response:\\n\", analytics_response)\n",
        "\n",
        "# Step 2: Run the graphing agent\n",
        "graph_response = graphing_agent.run(\"Generate a graph for AAPL stock trend.\")\n",
        "print(\"\\n📊 Graphing Agent Response:\\n\", graph_response)\n"
      ],
      "metadata": {
        "id": "ZxaXayThu8L8"
      },
      "id": "ZxaXayThu8L8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 📈 Stock Market and Investment Advice System\n",
        "# ================================\n",
        "# ✅ This system fetches stock analytics and provides investment advice by chaining two agents.\n",
        "\n",
        "import pandas as pd  # For handling CSV data\n",
        "from langchain.chat_models import ChatOpenAI  # LLM for reasoning and advice\n",
        "from langchain.agents import initialize_agent, AgentType  # Agent framework\n",
        "from langchain.tools import Tool  # Tool integration\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 1: Load AAPL Stock Data from Dropbox\n",
        "# ================================\n",
        "csv_url = \"https://www.dropbox.com/scl/fi/ysqxvj39gx2bkl4husg3y/HistoricalData_1739205046441.csv?rlkey=36q4rjpvvmwt9fyf3fftxwvb3&dl=1\"\n",
        "stock_data = pd.read_csv(csv_url)\n",
        "\n",
        "# 🔹 Format the \"Close/Last\" column (remove \"$\" sign and convert to float)\n",
        "stock_data['Close/Last'] = stock_data['Close/Last'].str.replace('$', '').astype(float)\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 2: Define the Stock Analytics Tool\n",
        "# ================================\n",
        "def get_aapl_analytics(query: str) -> str:\n",
        "    \"\"\"Fetch the latest stock data and provide analytics.\"\"\"\n",
        "    # Get the latest and previous stock data\n",
        "    latest_entry = stock_data.iloc[-1]\n",
        "    previous_entry = stock_data.iloc[-2]\n",
        "\n",
        "    # Calculate price change and percentage change\n",
        "    price_change = latest_entry['Close/Last'] - previous_entry['Close/Last']\n",
        "    price_change_percent = (price_change / previous_entry['Close/Last']) * 100\n",
        "\n",
        "    # Determine the trend direction\n",
        "    trend = \"upwards 📈\" if price_change > 0 else \"downwards 📉\"\n",
        "\n",
        "    # Generate analytics summary\n",
        "    analytics_summary = (\n",
        "        f\"📅 Date: {latest_entry['Date']}\\n\"\n",
        "        f\"🔹 Close Price: ${latest_entry['Close/Last']}\\n\"\n",
        "        f\"🔹 Price Change: {price_change:.2f} ({price_change_percent:.2f}%)\\n\"\n",
        "        f\"🔹 Trend: The stock is trending {trend}.\\n\"\n",
        "    )\n",
        "    return analytics_summary\n",
        "\n",
        "# 🔹 Register the analytics tool\n",
        "analytics_tool = Tool(\n",
        "    name=\"AAPL Stock Analytics\",\n",
        "    func=get_aapl_analytics,\n",
        "    description=\"Provides analytics for AAPL stock, including close price, price changes, and trend direction.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 3: Define the Investment Advice Agent\n",
        "# ================================\n",
        "def get_investment_advice(analytics_summary: str) -> str:\n",
        "    \"\"\"\n",
        "    Provides a brief investment recommendation based on the stock analytics.\n",
        "    \"\"\"\n",
        "    advice_prompt = (\n",
        "        f\"The following is the latest stock analysis for AAPL:\\n\"\n",
        "        f\"{analytics_summary}\\n\\n\"\n",
        "        f\"As a financial advisor, provide brief investment advice (e.g., buy, sell, or hold) \"\n",
        "        f\"with reasoning in 2 sentences.\"\n",
        "    )\n",
        "    return llm_investment.predict(advice_prompt)\n",
        "\n",
        "# 🔹 Register the investment advice tool\n",
        "investment_tool = Tool(\n",
        "    name=\"Investment Advice Generator\",\n",
        "    func=get_investment_advice,\n",
        "    description=\"Generates investment advice based on the latest stock analytics.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 4: Initialize the Two-Agent System\n",
        "# ================================\n",
        "\n",
        "# 🔹 Define the LLMs\n",
        "llm_analytics = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)  # For stock analysis\n",
        "llm_investment = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.0)  # For investment advice\n",
        "\n",
        "# 🔹 Create the stock analytics agent\n",
        "stock_agent = initialize_agent(\n",
        "    tools=[analytics_tool],\n",
        "    llm=llm_analytics,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 🔹 Create the investment advice agent\n",
        "investment_agent = initialize_agent(\n",
        "    tools=[investment_tool],\n",
        "    llm=llm_investment,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 5: Chain the Two Agents\n",
        "# ================================\n",
        "# 🔹 Get stock analytics from the first agent\n",
        "stock_query = \"Provide the latest stock analytics for AAPL.\"\n",
        "analytics_output = stock_agent.run(stock_query)\n",
        "\n",
        "# 🔹 Pass the analytics to the second agent for investment advice\n",
        "investment_query = analytics_output\n",
        "investment_advice = investment_agent.run(investment_query)\n",
        "\n",
        "# ================================\n",
        "# ✅ Step 6: Display the Final Output\n",
        "# ================================\n",
        "print(\"📊 Stock Analytics:\\n\", analytics_output)\n",
        "print(\"\\n💡 Investment Advice:\\n\", investment_advice)\n"
      ],
      "metadata": {
        "id": "9eVuJlQowUT-"
      },
      "id": "9eVuJlQowUT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgCEO_sawwO2"
      },
      "id": "KgCEO_sawwO2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}