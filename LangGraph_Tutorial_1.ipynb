{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH0Rn5rSzvtAi1PgxVdZ/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdehghani86/AppliedGenAI/blob/main/LangGraph_Tutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangGraph Lab : Part 1 üöÄ**\n",
        "- Prof. Dehghani\n",
        "## **Building More Controllable LLM Agents with LangGraph**\n",
        "\n",
        "## **Introduction**\n",
        "LangGraph is a framework designed for building **agent and multi-agent applications** with structured control. While large language models (LLMs) are powerful, they often require **more precise workflows** to ensure reliability.\n",
        "\n",
        "Many real-world applications need agents to follow **specific steps**, such as always calling a certain tool first or adjusting their prompts based on the current state. Traditional agent frameworks may not provide enough control for these scenarios. LangGraph introduces a **graph-based approach** that allows developers to define structured workflows while still benefiting from LLM flexibility.\n",
        "\n",
        "This lab is adapted from [LangChain Academy's Intro to LangGraph](https://academy.langchain.com/courses/intro-to-langgraph), which provides additional details and use cases.\n",
        "\n",
        "## **Lab Objectives**\n",
        "By the end of this lab, the following concepts will be covered:\n",
        "- The role of **graphs** in LLM-based agent workflows\n",
        "- How to define **nodes** (decision points) and **edges** (paths) in LangGraph\n",
        "- Implementing an **agent with controlled decision-making**\n",
        "- Exploring **multi-agent interactions** within a structured framework\n",
        "\n",
        "## **Getting Started**\n",
        "Run the following cell to install the required libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "-sCUJNA-pzym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUBqvLcsoxyf"
      },
      "outputs": [],
      "source": [
        "# üöÄ Install necessary libraries for LangGraph-based AI workflows\n",
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python langgraph wikipedia\n",
        "\n",
        "# langchain_openai: Official integration with OpenAI models for LLM-based tasks\n",
        "# langchain_core: Core framework for building and orchestrating LangChain applications\n",
        "# langchain_community: Additional community-contributed integrations and utilities\n",
        "# tavily-python: API client for web search, useful for Retrieval-Augmented Generation (RAG)\n",
        "# langgraph: Framework for creating AI-driven stateful workflows and decision graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Retrieve OpenAI API key securely from Colab's userdata storage\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OpenAI_Key')  # Fetch the stored API key\n",
        "\n",
        "# Ensure the key is set as an environment variable\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"‚úÖ OpenAI API key successfully set.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è OpenAI API key not found. Please store it using Colab's userdata feature.\")\n"
      ],
      "metadata": {
        "id": "dCcipqIhrJmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Using GPT-4o and GPT-3.5 in LangChain  \n",
        "\n",
        "This section initializes **GPT-4o** and **GPT-3.5 Turbo** models using LangChain.  \n",
        "It demonstrates how to:  \n",
        "- Create a **human message** and send it as part of a conversation.  \n",
        "- Invoke both models with **single text inputs** and **message lists**.  \n",
        "- Print the responses for comparison.  \n",
        "\n",
        "Run the code to see how different models respond to the same input.\n"
      ],
      "metadata": {
        "id": "dfy7PTgGrxEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Initialize OpenAI Chat Models (GPT-4o & GPT-3.5)\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Set up GPT-4o and GPT-3.5 Turbo with zero temperature for deterministic responses\n",
        "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "# üó£Ô∏è Create a human message instance\n",
        "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
        "\n",
        "# Store the message inside a list (models expect message sequences)\n",
        "messages = [msg]\n",
        "\n",
        "#  Invoke the GPT-4o model with a message list\n",
        "response_4o = gpt4o_chat.invoke(messages)\n",
        "\n",
        "#  Invoke the GPT-4o and GPT-3.5 models with a simple text prompt\n",
        "response_4o_text = gpt4o_chat.invoke(\"hello world\")\n",
        "response_35_text = gpt35_chat.invoke(\"hello world\")\n",
        "\n",
        "# ‚úÖ Display responses\n",
        "print(\"GPT-4o Response:\", response_4o)\n",
        "print(\"GPT-4o (Text) Response:\", response_4o_text)\n",
        "print(\"GPT-3.5 Response:\", response_35_text)\n"
      ],
      "metadata": {
        "id": "HJU_ydrxrJ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîé What is Tavily?  \n",
        "\n",
        "[Tavily](https://tavily.com/) is a web search API that allows AI applications to retrieve real-time information from the internet.  \n",
        "It is commonly used in *retrieval-augmented generation (RAG)* systems, where an LLM enhances responses by fetching *up-to-date* and relevant data from external sources.  \n",
        "\n",
        "In this lab, Tavily will be used to perform web searches and integrate real-world information into LangGraph workflows.  \n"
      ],
      "metadata": {
        "id": "TFrC1ADBsQRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Retrieve Tavily API key securely from Colab's userdata storage\n",
        "tavily_api_key = userdata.get('Tavily_Key')  # Fetch the stored API key\n",
        "\n",
        "# Ensure the key is set as an environment variable\n",
        "if tavily_api_key:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
        "    print(\"‚úÖ Tavily API key successfully set.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Tavily API key not found. Please store it using Colab's userdata feature.\")\n"
      ],
      "metadata": {
        "id": "yEHHfRr6rpZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Using Tavily for Web Search in LangChain\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Initialize Tavily search tool with a maximum of 3 results\n",
        "tavily_search = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Perform a web search query\n",
        "query = \"What is LangGraph?\"\n",
        "search_docs = tavily_search.invoke(query)\n",
        "\n",
        "# ‚úÖ Display the retrieved search results\n",
        "print(\"üîπ Tavily Search Results for:\", query)\n",
        "print(search_docs)\n"
      ],
      "metadata": {
        "id": "sNHGFpEisuN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Simplest Graph  \n",
        "\n",
        "Let's build a simple graph with **three nodes** and **one conditional edge**. This structure allows an agent to make a decision at a branching point, directing the flow based on predefined conditions.  \n",
        "\n",
        "<img src=\"https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dba5f465f6e9a2482ad935_simple-graph1.png\" width=\"600\"/>  \n",
        "\n",
        "This example demonstrates how **LangGraph** enables structured decision-making while maintaining flexibility.  \n"
      ],
      "metadata": {
        "id": "iPZfc7FKtqXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Understanding Graph Components  \n",
        "\n",
        "LangGraph workflows consist of **three main components**: *State, Nodes, and Edges*. Each plays a key role in defining how information flows through the graph.  \n",
        "\n",
        "---\n",
        "\n",
        "## üß† State  \n",
        "\n",
        "The **State** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)) acts as the **shared memory** of the graph, storing data that nodes can read and modify.  \n",
        "\n",
        "- Every *node and edge* interacts with the state.  \n",
        "- It is defined using `TypedDict` from Python‚Äôs `typing` module, which helps structure data with type hints.  \n",
        "- Nodes modify the state by updating specific keys.  \n",
        "\n",
        "---\n",
        "\n",
        "## üîµ Nodes  \n",
        "\n",
        "A **Node** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes)) is a simple **Python function** that processes the state.  \n",
        "\n",
        "- The **first argument** of a node function is always the *state*.  \n",
        "- Nodes can *read and modify* the state using keys like `state['graph_state']`.  \n",
        "- By default, when a node returns a value, it updates the state and replaces the previous value ([reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) handle this).  \n",
        "\n",
        "---\n",
        "\n",
        "## üîÄ Edges  \n",
        "\n",
        "An **Edge** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges)) connects nodes and controls how data moves between them.  \n",
        "\n",
        "Two types of edges exist:  \n",
        "- **Normal Edges** ‚Üí Always transition from one node to the next (e.g., `node_1 ‚Üí node_2`).  \n",
        "- **Conditional Edges** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)) ‚Üí Decide the next node dynamically based on logic.  \n",
        "\n",
        "Conditional edges *act like decision points*, determining the next step in the workflow.  \n"
      ],
      "metadata": {
        "id": "ldOostBhtwUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Literal\n",
        "import random\n",
        "\n",
        "# üéØ Define the State Schema\n",
        "# The state acts as shared memory for the graph.\n",
        "# It stores a key-value pair where 'graph_state' holds a string that evolves as nodes modify it.\n",
        "class State(TypedDict):\n",
        "    graph_state: str  # Tracks the sentence as it builds through the nodes\n",
        "\n",
        "# üîµ Define Nodes\n",
        "# Each node modifies the 'graph_state' by appending its own text.\n",
        "# Nodes simulate a simple sentence-building process.\n",
        "\n",
        "def node_1(state: State) -> State:\n",
        "    \"\"\"Node 1 initializes the sentence with 'I am'.\"\"\"\n",
        "    print(\"--- Node 1 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" I am\"}\n",
        "\n",
        "def node_2(state: State) -> State:\n",
        "    \"\"\"Node 2 completes the sentence with 'happy!'.\"\"\"\n",
        "    print(\"--- Node 2 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" happy!\"}\n",
        "\n",
        "def node_3(state: State) -> State:\n",
        "    \"\"\"Node 3 completes the sentence with 'sad!'.\"\"\"\n",
        "    print(\"--- Node 3 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" sad!\"}\n",
        "\n",
        "# üîÄ Define the Decision Function\n",
        "# This function decides whether to send the state to Node 2 or Node 3.\n",
        "# It randomly picks between the two, simulating an unpredictable emotional outcome.\n",
        "\n",
        "def decide_mood(state: State) -> Literal[\"node_2\", \"node_3\"]:\n",
        "    \"\"\"Randomly selects between Node 2 (happy) and Node 3 (sad).\"\"\"\n",
        "\n",
        "    # Simulate a 50/50 decision\n",
        "    if random.random() < 0.5:\n",
        "        return \"node_2\"  # 50% chance to go to Node 2 (happy)\n",
        "    return \"node_3\"  # 50% chance to go to Node 3 (sad)\n"
      ],
      "metadata": {
        "id": "rSoT9P3NtseJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Graph Construction  \n",
        "\n",
        "Now, it's time to build the graph using the **components** defined earlier. The **StateGraph class** is used to create and manage the graph structure.  \n",
        "\n",
        "### üèóÔ∏è Steps to Build the Graph  \n",
        "1. **Initialize the Graph** ‚Üí Create a `StateGraph` using the `State` class.  \n",
        "2. **Add Nodes and Edges** ‚Üí Define how the graph flows.  \n",
        "3. **Use Special Nodes**:  \n",
        "   - **`START` Node** ‚Üí Sends user input into the graph.  \n",
        "   - **`END` Node** ‚Üí Represents a terminal state.  \n",
        "4. **Compile the Graph** ‚Üí Ensures structural validity.  \n",
        "5. **Visualize** ‚Üí Convert it into a **Mermaid diagram** for better understanding.  \n",
        "\n",
        "### üîó Reference Table  \n",
        "\n",
        "| Concept       | Documentation Link |\n",
        "|--------------|------------------|\n",
        "| StateGraph Class | [StateGraph Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) |\n",
        "| START Node   | [START Node Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) |\n",
        "| END Node     | [END Node Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) |\n",
        "| Graph Compilation | [Compiling a Graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) |\n",
        "| Mermaid Diagrams | [Mermaid Docs](https://github.com/mermaid-js/mermaid) |\n",
        "\n",
        "This approach makes the graph more **structured, adaptable, and easy to debug**.  \n"
      ],
      "metadata": {
        "id": "lrjO8J8DvENy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# üèóÔ∏è Initialize the Graph Builder\n",
        "# The StateGraph is created using the State schema defined earlier.\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# üîµ Add Nodes\n",
        "# Each node represents a step in the process and modifies the graph_state.\n",
        "builder.add_node(\"node_1\", node_1)  # Starts the sentence\n",
        "builder.add_node(\"node_2\", node_2)  # Appends \"happy!\"\n",
        "builder.add_node(\"node_3\", node_3)  # Appends \"sad!\"\n",
        "\n",
        "# üîó Define Graph Flow (Edges)\n",
        "# Edges define how nodes connect to each other.\n",
        "\n",
        "# The START node sends input to \"node_1\"\n",
        "builder.add_edge(START, \"node_1\")\n",
        "\n",
        "# From \"node_1\", the next step is decided dynamically using the decide_mood function.\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "\n",
        "# \"node_2\" (happy) and \"node_3\" (sad) both lead to the END node.\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# ‚úÖ Compile the Graph\n",
        "# This ensures that the structure is valid and ready for execution.\n",
        "graph = builder.compile()\n",
        "\n",
        "# üñºÔ∏è Visualize the Graph\n",
        "# Generates a Mermaid diagram to display the flow of nodes and edges.\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "id": "OskefMiJvDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Invocation  \n",
        "\n",
        "The compiled graph follows the [runnable](https://python.langchain.com/docs/concepts/runnables/) protocol, providing a standardized way to execute LangChain components. The `invoke` method is used to start execution, with an input dictionary like `{\"graph_state\": \"Hi, this is Lance.\"}` setting the initial state. The graph begins at the `START` node and moves through the defined nodes (`node_1`, `node_2`, `node_3`) based on the control flow. A conditional edge determines whether the execution moves from `node_1` to `node_2` or `node_3`, following a 50/50 probability rule. Each node processes the current state, modifies the `graph_state` value, and returns the updated state. The execution continues along the directed edges until it reaches the `END` node, where the final graph state is returned.\n"
      ],
      "metadata": {
        "id": "c9PlWY6jvvf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
      ],
      "metadata": {
        "id": "1tEzUm9QveUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úàÔ∏è Airport Security Screening Simulation (LangGraph Hands-On)\n",
        "\n",
        "## üõ´ Scenario\n",
        "In this exercise, we simulate an **airport security screening process** using **LangGraph**. Passengers arrive at security and are categorized into:\n",
        "1. **TSA PreCheck (20%)** ‚Üí Fast screening\n",
        "2. **Regular Screening (80%)** ‚Üí Standard security check\n",
        "3. **Additional Screening (10% of Regular Passengers)** ‚Üí Extra checks before proceeding to gates\n",
        "\n",
        "Below is a **visual representation** of the screening process:\n",
        "\n",
        "![Airport Security Flow](https://www.dropbox.com/scl/fi/o3ipy33svrcg64myu0u0s/AirPort_Security.png?rlkey=d6hc4bqdphzducnixba9ic2ai&dl=1)\n",
        "\n",
        "---\n",
        "## Task: Complete the Missing Code\n",
        "Your goal is to **fill in the placeholders (`-------`)** to define functions and logic in the LangGraph framework.\n"
      ],
      "metadata": {
        "id": "qZ3g3hX9aZ_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Literal\n",
        "import random\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "\n",
        "# üéØ Define the State Schema\n",
        "class AirportState(TypedDict):\n",
        "    passenger_type: str  # Tracks whether passenger is Regular or TSA PreCheck\n",
        "\n",
        "# üîµ Define Nodes\n",
        "def start_node(state: AirportState) -> AirportState:\n",
        "    \"\"\"Initial step where a passenger enters security.\"\"\"\n",
        "    print(\"üõ´ Passenger arrives at security.\")\n",
        "    return state\n",
        "\n",
        "def tsa_screening(state: -------) -> -------:\n",
        "    \"\"\"TSA PreCheck passengers go through expedited screening.\"\"\"\n",
        "    print(\"üü¢ TSA PreCheck passenger goes through expedited screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_screening(state: -------) -> -------:\n",
        "    \"\"\"Regular passengers go through standard screening.\"\"\"\n",
        "    print(\"üîé Regular passenger goes through standard screening.\")\n",
        "    return state\n",
        "\n",
        "def additional_screening(state: -------) -> -------:\n",
        "    \"\"\"Additional screening for some regular passengers.\"\"\"\n",
        "    print(\"‚ö†Ô∏è Additional screening required for passenger.\")\n",
        "    return -------\n",
        "\n",
        "def gates(state: -------) -> -------:\n",
        "    \"\"\"All passengers proceed to the boarding gates.\"\"\"\n",
        "    print(\"‚úÖ Passenger cleared security. Proceeding to Gates!\")\n",
        "    return -------\n",
        "\n",
        "# üîÄ Define the First Decision Function (TSA or Regular)\n",
        "def assign_passenger_type(state: -------) -> Literal[\"-------\", \"-------\"]:\n",
        "    \"\"\"Randomly assigns passengers to TSA PreCheck (20%) or Regular (80%).\"\"\"\n",
        "    if random.random() < -------:\n",
        "        print(\"üü¢ Passenger assigned to TSA PreCheck.\")\n",
        "        return \"tsa_screening\"\n",
        "    else:\n",
        "        print(\"üîµ Passenger assigned to Regular Screening.\")\n",
        "        return \"regular_screening\"\n",
        "\n",
        "# üîÄ Define the Second Decision Function (Regular -> Additional Screening or Gates)\n",
        "def additional_screening_decision(state: -------) -> -------[\"-------\", \"-------\"]:\n",
        "    \"\"\"10% of regular passengers go to additional screening, while 90% proceed to gates.\"\"\"\n",
        "    if random.random() < -------:\n",
        "        print(\"‚ö†Ô∏è Passenger selected for additional screening.\")\n",
        "        return \"-------\"\n",
        "    else:\n",
        "        print(\"‚úÖ Passenger cleared security after regular screening.\")\n",
        "        return \"-------\"\n",
        "\n",
        "# üèóÔ∏è Build the Graph\n",
        "builder = StateGraph(-------)\n",
        "\n",
        "# üîµ Add Nodes\n",
        "builder.-------(\"start_node\", -------)\n",
        "builder.add_node(\"tsa_screening\", -------)\n",
        "builder.add_node(\"regular_screening\", -------)\n",
        "builder.add_node(\"additional_screening\", -------)\n",
        "builder.add_node(\"gates\", -------)\n",
        "\n",
        "# üîó Define Graph Flow (Edges)\n",
        "builder.-------(START, \"-------\")\n",
        "builder.add_conditional_edges(\"start_node\", -------)\n",
        "builder.add_edge(\"tsa_screening\", \"-------\")\n",
        "builder.add_conditional_edges(\"regular_screening\", -------)\n",
        "builder.add_edge(\"additional_screening\", \"-------\")\n",
        "builder.add_edge(\"gates\", END)\n",
        "\n",
        "# ‚úÖ Compile the Graph\n",
        "graph = builder.-------\n",
        "\n",
        "# üñºÔ∏è Visualize the Graph\n",
        "display(Image(graph.get_graph().-------))\n",
        "\n",
        "# üöÄ Run the Graph\n",
        "graph.-------({})\n"
      ],
      "metadata": {
        "id": "QzWO66tmcQ3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # üîÑ Test your code: Refresh this cell to see how the model works on different scenarios\n",
        "\n",
        "graph.invoke({})"
      ],
      "metadata": {
        "id": "hpXoYKguedp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xCbYMpqNhaEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Annotated\n",
        "from typing import Literal\n",
        "import random\n",
        "import json\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "\n",
        "# üîë Secure OpenAI API Key\n",
        "OPENAI_API_KEY = userdata.get('OpenAI_Key')\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, api_key=OPENAI_API_KEY)\n",
        "\n",
        "# üéØ Define State Schema\n",
        "class AirportState(TypedDict):\n",
        "    passenger_type: str  # \"TSA\" or \"Regular\"\n",
        "    luggage: Annotated[list, \"merge\"]  # Luggage details (set once)\n",
        "    screening_notes: Annotated[list, \"merge\"]  # Screening decisions\n",
        "    flagged: bool  # True if extra screening is needed\n",
        "\n",
        "# üèóÔ∏è Initialize Persistent Memory\n",
        "memory_store = {\"total_passengers\": 0, \"flagged_passengers\": 0}\n",
        "\n",
        "def create_passenger(state: AirportState) -> AirportState:\n",
        "    \"\"\"Creates a passenger and assigns luggage.\"\"\"\n",
        "    print(\"üõ´ Passenger enters airport security.\")\n",
        "\n",
        "    # Generate luggage inside this function\n",
        "    if \"luggage\" not in state or not state[\"luggage\"]:\n",
        "\n",
        "        # üîÄ Random chance to include dangerous items (10% of the time)\n",
        "        if random.random() < 0.3:\n",
        "            prompt = (\n",
        "                \"List 6-10 items in the passenger's luggage, including 1-2 dangerous items \"\n",
        "                \"that might require extra screening. Format response as a JSON list.\"\n",
        "                \"(Example: [\\\"Laptop\\\", \\\"Water Bottle\\\", \\\"Pocket Knife\\\", \\\"Lighter\\\"])\"\n",
        "            )\n",
        "            print(\"‚ö†Ô∏è Generating luggage with potential dangerous items...\")\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"List 6-10 common travel items in the passenger's luggage. \"\n",
        "                \"Do NOT include dangerous items. Format response as a JSON list.\"\n",
        "                \"(Example: [\\\"Backpack\\\", \\\"Sunglasses\\\", \\\"Travel Pillow\\\", \\\"Shoes\\\"])\"\n",
        "            )\n",
        "\n",
        "        # üß† Get response from LLM\n",
        "        response = llm([HumanMessage(content=prompt)])\n",
        "\n",
        "        try:\n",
        "            items = json.loads(response.content)\n",
        "            if isinstance(items, list):\n",
        "                state[\"luggage\"] = items\n",
        "            else:\n",
        "                raise ValueError(\"Invalid format received from LLM.\")\n",
        "        except json.JSONDecodeError:\n",
        "            state[\"luggage\"] = [\"Unknown Item\"]  # Fallback\n",
        "\n",
        "    print(f\"üéí Luggage: {state['luggage']}\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def assign_lane(state: AirportState) -> Literal[\"tsa_entry\", \"regular_entry\"]:\n",
        "    \"\"\"Assigns passenger to TSA or Regular screening.\"\"\"\n",
        "    if random.random() < 0.3:\n",
        "        print(\"üü¢ Passenger is TSA PreCheck.\")\n",
        "        state[\"passenger_type\"] = \"TSA\"\n",
        "        return \"tsa_entry\"\n",
        "    else:\n",
        "        print(\"üîµ Passenger is Regular Screening.\")\n",
        "        state[\"passenger_type\"] = \"Regular\"\n",
        "        return \"regular_entry\"\n",
        "\n",
        "# ‚úÖ TSA-ONLY SCREENING PATH\n",
        "def tsa_entry(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passengers enter the TSA checkpoint.\"\"\"\n",
        "    print(\"üü¢ TSA passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_scan(state: AirportState) -> AirportState:\n",
        "    \"\"\"AI scans TSA passenger luggage for prohibited items.\"\"\"\n",
        "    return run_ai_screening(state, \"TSA\")\n",
        "\n",
        "def tsa_decision(state: AirportState) -> Literal[\"tsa_extra\", \"tsa_clear\"]:\n",
        "    \"\"\"Determines if TSA passenger needs extra screening.\"\"\"\n",
        "    return \"tsa_extra\" if state[\"flagged\"] else \"tsa_clear\"\n",
        "\n",
        "def tsa_extra(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passengers flagged for extra screening.\"\"\"\n",
        "    print(\"‚ö†Ô∏è TSA passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"TSA passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_clear(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passenger cleared to board.\"\"\"\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "# ‚úÖ REGULAR-ONLY SCREENING PATH\n",
        "def regular_entry(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passengers enter the standard security checkpoint.\"\"\"\n",
        "    print(\"üîé Regular passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_scan(state: AirportState) -> AirportState:\n",
        "    \"\"\"AI scans Regular passenger luggage for prohibited items.\"\"\"\n",
        "    return run_ai_screening(state, \"Regular\")\n",
        "\n",
        "def regular_decision(state: AirportState) -> Literal[\"regular_extra\", \"regular_clear\"]:\n",
        "    \"\"\"Determines if Regular passenger needs extra screening.\"\"\"\n",
        "    return \"regular_extra\" if state[\"flagged\"] else \"regular_clear\"\n",
        "\n",
        "def regular_extra(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passengers flagged for extra screening.\"\"\"\n",
        "    print(\"‚ö†Ô∏è Regular passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"Regular passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_clear(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passenger cleared to board.\"\"\"\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "# ‚úÖ COMMON FINAL NODE\n",
        "def proceed_to_gates(state: AirportState) -> AirportState:\n",
        "    \"\"\"Passengers cleared from both TSA & Regular screenings go to gates.\"\"\"\n",
        "    print(\"‚úÖ Passenger cleared security. Proceeding to gates!\")\n",
        "    return state\n",
        "\n",
        "# ‚úÖ AI SCREENING FUNCTION (Shared)\n",
        "def run_ai_screening(state: AirportState, passenger_type: str) -> AirportState:\n",
        "    \"\"\"AI determines if luggage requires additional screening.\"\"\"\n",
        "    global memory_store  # ‚úÖ Track memory stats here\n",
        "\n",
        "    prompt = f\"Luggage: {state['luggage']}. Should this {passenger_type} passenger be flagged? Answer 'Yes' or 'No' with a short reason.\"\n",
        "    response = llm([HumanMessage(content=prompt)])\n",
        "\n",
        "    state[\"flagged\"] = \"yes\" in response.content.lower()\n",
        "    state.setdefault(\"screening_notes\", []).append(response.content)\n",
        "\n",
        "    # ‚úÖ Update global memory stats\n",
        "    memory_store[\"total_passengers\"] += 1\n",
        "    if state[\"flagged\"]:\n",
        "        memory_store[\"flagged_passengers\"] += 1\n",
        "\n",
        "    decision = \"‚ö†Ô∏è Extra Screening Required!\" if state[\"flagged\"] else \"‚úÖ Cleared for Gates.\"\n",
        "    print(f\"üõÉ AI Screening Decision: {decision} ({response.content})\")\n",
        "\n",
        "    return state\n",
        "\n",
        "# üèóÔ∏è Build Graph\n",
        "builder = StateGraph(AirportState)\n",
        "\n",
        "# üîµ Add Nodes\n",
        "builder.add_node(\"create_passenger\", create_passenger)\n",
        "builder.add_node(\"tsa_entry\", tsa_entry)\n",
        "builder.add_node(\"regular_entry\", regular_entry)\n",
        "builder.add_node(\"tsa_scan\", tsa_scan)\n",
        "builder.add_node(\"regular_scan\", regular_scan)\n",
        "builder.add_node(\"tsa_extra\", tsa_extra)\n",
        "builder.add_node(\"regular_extra\", regular_extra)\n",
        "builder.add_node(\"tsa_clear\", tsa_clear)\n",
        "builder.add_node(\"regular_clear\", regular_clear)\n",
        "builder.add_node(\"proceed_to_gates\", proceed_to_gates)\n",
        "\n",
        "# üîó Define Flow\n",
        "builder.add_edge(START, \"create_passenger\")\n",
        "builder.add_conditional_edges(\"create_passenger\", assign_lane)\n",
        "\n",
        "# TSA Path\n",
        "builder.add_edge(\"tsa_entry\", \"tsa_scan\")\n",
        "builder.add_conditional_edges(\"tsa_scan\", tsa_decision)\n",
        "builder.add_edge(\"tsa_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"tsa_clear\", \"proceed_to_gates\")\n",
        "\n",
        "# Regular Path\n",
        "builder.add_edge(\"regular_entry\", \"regular_scan\")\n",
        "builder.add_conditional_edges(\"regular_scan\", regular_decision)\n",
        "builder.add_edge(\"regular_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"regular_clear\", \"proceed_to_gates\")\n",
        "\n",
        "builder.add_edge(\"proceed_to_gates\", END)\n",
        "\n",
        "# ‚úÖ Compile and Run\n",
        "graph = builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# üöÄ Run for Multiple Passengers\n",
        "for _ in range(6):  # Process 10 passengers in a single run\n",
        "    print(\"\\nüöÄ Processing New Passenger üöÄ\")\n",
        "    graph.invoke({})\n",
        "    # ‚úÖ Print Final Stats from Memory\n",
        "    print(f\"\\nüìà FINAL STATS: {memory_store['total_passengers']} Total, {memory_store['flagged_passengers']} Flagged\")\n"
      ],
      "metadata": {
        "id": "1XY69unrvwYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ LangGraph with Human in the Loop üîÑ\n",
        "\n",
        "**Definition:**  \n",
        "\"Human in the Loop\" refers to a workflow design where automated systems (such as AI and LangGraph) handle routine tasks, but key decisions are deferred to human judgment. This hybrid approach ensures that while the system processes data efficiently, a human can review and override decisions when necessary.\n",
        "\n",
        "**Why It's Important:**  \n",
        "- **‚úÖ Quality Assurance:** Humans can catch subtleties and errors that automated processes may overlook.  \n",
        "- **‚ö†Ô∏è Risk Mitigation:** Critical decisions benefit from human oversight, reducing potential risks from misclassification or errors.  \n",
        "- **üîß Adaptability:** Human feedback enables continuous improvement and adjustment of the automated system.\n",
        "\n",
        "**Application in This Lab:**  \n",
        "In this lab, the LangGraph system automatically screens passengers. If a passenger is flagged, the AI generates a 2-3 sentence comment describing potential risks. Then, a dropdown is presented for the user to decide whether to **\"Pass\"** or **\"Reject\"** the flagged passenger. This integration ensures that while automation speeds up the process, human insight remains central to final decision-making.\n"
      ],
      "metadata": {
        "id": "XvjjWEcnukD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Annotated\n",
        "from typing import Literal\n",
        "import random\n",
        "import json\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "\n",
        "# üîë Secure OpenAI API Key\n",
        "OPENAI_API_KEY = userdata.get('OpenAI_Key')\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, api_key=OPENAI_API_KEY)\n",
        "\n",
        "# üéØ Define State Schema\n",
        "class AirportState(TypedDict):\n",
        "    passenger_type: str  # \"TSA\" or \"Regular\"\n",
        "    luggage: Annotated[list, \"merge\"]  # Luggage details (set once)\n",
        "    screening_notes: Annotated[list, \"merge\"]  # Screening decisions\n",
        "    flagged: bool  # True if extra screening is needed\n",
        "\n",
        "# üèóÔ∏è Initialize Persistent Memory\n",
        "memory_store = {\"total_passengers\": 0, \"flagged_passengers\": 0}\n",
        "\n",
        "def create_passenger(state: AirportState) -> AirportState:\n",
        "    \"\"\"Creates a passenger and assigns luggage.\"\"\"\n",
        "    print(\"üõ´ Passenger enters airport security.\")\n",
        "\n",
        "    # Generate luggage inside this function\n",
        "    if \"luggage\" not in state or not state[\"luggage\"]:\n",
        "        # üîÄ Random chance to include dangerous items (10% of the time)\n",
        "        if random.random() < 0.3:\n",
        "            prompt = (\n",
        "                \"List 6-10 items in the passenger's luggage, including 1-2 dangerous items \"\n",
        "                \"that might require extra screening. Format response as a JSON list.\"\n",
        "                \"(Example: [\\\"Laptop\\\", \\\"Water Bottle\\\", \\\"Pocket Knife\\\", \\\"Lighter\\\"])\"\n",
        "            )\n",
        "            print(\"‚ö†Ô∏è Generating luggage with potential dangerous items...\")\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"List 6-10 common travel items in the passenger's luggage. \"\n",
        "                \"Do NOT include dangerous items. Format response as a JSON list.\"\n",
        "                \"(Example: [\\\"Backpack\\\", \\\"Sunglasses\\\", \\\"Travel Pillow\\\", \\\"Shoes\\\"])\"\n",
        "            )\n",
        "\n",
        "        # üß† Get response from LLM\n",
        "        response = llm([HumanMessage(content=prompt)])\n",
        "\n",
        "        try:\n",
        "            items = json.loads(response.content)\n",
        "            if isinstance(items, list):\n",
        "                state[\"luggage\"] = items\n",
        "            else:\n",
        "                raise ValueError(\"Invalid format received from LLM.\")\n",
        "        except json.JSONDecodeError:\n",
        "            state[\"luggage\"] = [\"Unknown Item\"]  # Fallback\n",
        "\n",
        "    print(f\"üéí Luggage: {state['luggage']}\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def assign_lane(state: AirportState) -> Literal[\"tsa_entry\", \"regular_entry\"]:\n",
        "    \"\"\"Assigns passenger to TSA or Regular screening.\"\"\"\n",
        "    if random.random() < 0.3:\n",
        "        print(\"üü¢ Passenger is TSA PreCheck.\")\n",
        "        state[\"passenger_type\"] = \"TSA\"\n",
        "        return \"tsa_entry\"\n",
        "    else:\n",
        "        print(\"üîµ Passenger is Regular Screening.\")\n",
        "        state[\"passenger_type\"] = \"Regular\"\n",
        "        return \"regular_entry\"\n",
        "\n",
        "# ‚úÖ TSA-ONLY SCREENING PATH\n",
        "def tsa_entry(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passengers enter the TSA checkpoint.\"\"\"\n",
        "    print(\"üü¢ TSA passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_scan(state: AirportState) -> AirportState:\n",
        "    \"\"\"AI scans TSA passenger luggage for prohibited items.\"\"\"\n",
        "    return run_ai_screening(state, \"TSA\")\n",
        "\n",
        "def tsa_decision(state: AirportState) -> Literal[\"tsa_extra\", \"tsa_clear\"]:\n",
        "    \"\"\"Determines if TSA passenger needs extra screening.\"\"\"\n",
        "    return \"tsa_extra\" if state[\"flagged\"] else \"tsa_clear\"\n",
        "\n",
        "def tsa_extra(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passengers flagged for extra screening.\"\"\"\n",
        "    print(\"‚ö†Ô∏è TSA passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"TSA passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_clear(state: AirportState) -> AirportState:\n",
        "    \"\"\"TSA passenger cleared to board.\"\"\"\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "# ‚úÖ REGULAR-ONLY SCREENING PATH\n",
        "def regular_entry(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passengers enter the standard security checkpoint.\"\"\"\n",
        "    print(\"üîé Regular passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_scan(state: AirportState) -> AirportState:\n",
        "    \"\"\"AI scans Regular passenger luggage for prohibited items.\"\"\"\n",
        "    return run_ai_screening(state, \"Regular\")\n",
        "\n",
        "def regular_decision(state: AirportState) -> Literal[\"regular_extra\", \"regular_clear\"]:\n",
        "    \"\"\"Determines if Regular passenger needs extra screening.\"\"\"\n",
        "    return \"regular_extra\" if state[\"flagged\"] else \"regular_clear\"\n",
        "\n",
        "def regular_extra(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passengers flagged for extra screening.\"\"\"\n",
        "    print(\"‚ö†Ô∏è Regular passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"Regular passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_clear(state: AirportState) -> AirportState:\n",
        "    \"\"\"Regular passenger cleared to board.\"\"\"\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "# ‚úÖ COMMON FINAL NODE\n",
        "def proceed_to_gates(state: AirportState) -> AirportState:\n",
        "    \"\"\"Passengers cleared from both TSA & Regular screenings go to gates.\"\"\"\n",
        "    print(\"‚úÖ Passenger cleared security. Proceeding to gates!\")\n",
        "    return state\n",
        "\n",
        "# ‚úÖ AI SCREENING FUNCTION (Shared with LLM providing comment & text input for decision)\n",
        "def run_ai_screening(state: AirportState, passenger_type: str) -> AirportState:\n",
        "    \"\"\"AI determines if luggage requires additional screening. If flagged, provide a 2-3 sentence comment\n",
        "    and prompt the user with a Y/N text input for decision before proceeding.\"\"\"\n",
        "    global memory_store  # ‚úÖ Track memory stats here\n",
        "\n",
        "    # Initial screening prompt\n",
        "    prompt = f\"Luggage: {state['luggage']}. Should this {passenger_type} passenger be flagged? Answer 'Yes' or 'No' with a short reason.\"\n",
        "    response = llm([HumanMessage(content=prompt)])\n",
        "    state[\"flagged\"] = \"yes\" in response.content.lower()\n",
        "    state.setdefault(\"screening_notes\", []).append(response.content)\n",
        "\n",
        "    # ‚úÖ Update global memory stats\n",
        "    memory_store[\"total_passengers\"] += 1\n",
        "    if state[\"flagged\"]:\n",
        "        memory_store[\"flagged_passengers\"] += 1\n",
        "\n",
        "        # +++ UPDATED: For flagged passengers, have the LLM provide a 2-3 sentence comment.\n",
        "        comment_prompt = (\n",
        "            f\"Passenger Flagged: Luggage Items: {state['luggage']}. \"\n",
        "            \"Please provide a brief, 2-3 sentence comment that explains the potential risks associated with these items.\"\n",
        "        )\n",
        "        comment_response = llm([HumanMessage(content=comment_prompt)])\n",
        "        state.setdefault(\"screening_notes\", []).append(\"Flagged Comment: \" + comment_response.content)\n",
        "        print(f\"üõÉ LLM Comment on Flagged Passenger: {comment_response.content}\")\n",
        "\n",
        "        # +++ UPDATED: Prompt the user with a text input for decision (Y/N).\n",
        "        user_input = input(\"Flagged passenger. Enter Y to Pass or N to Reject: \").strip().lower()  # Y/N input\n",
        "        while user_input not in ['y', 'n']:\n",
        "            print(\"Invalid input. Please enter Y or N.\")\n",
        "            user_input = input(\"Flagged passenger. Enter Y to Pass or N to Reject: \").strip().lower()\n",
        "        user_decision = \"pass\" if user_input == 'y' else \"reject\"\n",
        "        state.setdefault(\"screening_notes\", []).append(\"User Decision: \" + user_decision)\n",
        "        print(f\"User Decision on flagged passenger: {user_decision}\")\n",
        "\n",
        "    decision = \"‚ö†Ô∏è Extra Screening Required!\" if state[\"flagged\"] else \"‚úÖ Cleared for Gates.\"\n",
        "    print(f\"üõÉ AI Screening Decision: {decision} ({response.content})\")\n",
        "\n",
        "    return state\n",
        "\n",
        "# üèóÔ∏è Build Graph\n",
        "builder = StateGraph(AirportState)\n",
        "\n",
        "# üîµ Add Nodes\n",
        "builder.add_node(\"create_passenger\", create_passenger)\n",
        "builder.add_node(\"tsa_entry\", tsa_entry)\n",
        "builder.add_node(\"regular_entry\", regular_entry)\n",
        "builder.add_node(\"tsa_scan\", tsa_scan)\n",
        "builder.add_node(\"regular_scan\", regular_scan)\n",
        "builder.add_node(\"tsa_extra\", tsa_extra)\n",
        "builder.add_node(\"regular_extra\", regular_extra)\n",
        "builder.add_node(\"tsa_clear\", tsa_clear)\n",
        "builder.add_node(\"regular_clear\", regular_clear)\n",
        "builder.add_node(\"proceed_to_gates\", proceed_to_gates)\n",
        "\n",
        "# üîó Define Flow\n",
        "builder.add_edge(START, \"create_passenger\")\n",
        "builder.add_conditional_edges(\"create_passenger\", assign_lane)\n",
        "\n",
        "# TSA Path\n",
        "builder.add_edge(\"tsa_entry\", \"tsa_scan\")\n",
        "builder.add_conditional_edges(\"tsa_scan\", tsa_decision)\n",
        "builder.add_edge(\"tsa_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"tsa_clear\", \"proceed_to_gates\")\n",
        "\n",
        "# Regular Path\n",
        "builder.add_edge(\"regular_entry\", \"regular_scan\")\n",
        "builder.add_conditional_edges(\"regular_scan\", regular_decision)\n",
        "builder.add_edge(\"regular_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"regular_clear\", \"proceed_to_gates\")\n",
        "\n",
        "builder.add_edge(\"proceed_to_gates\", END)\n",
        "\n",
        "# ‚úÖ Compile and Run\n",
        "graph = builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# üöÄ Run for Multiple Passengers\n",
        "for _ in range(6):  # Process 6 passengers in a single run\n",
        "    print(\"\\nüöÄ Processing New Passenger üöÄ\")\n",
        "    graph.invoke({})\n",
        "    # ‚úÖ Print Final Stats from Memory\n",
        "    print(f\"\\nüìà FINAL STATS: {memory_store['total_passengers']} Total, {memory_store['flagged_passengers']} Flagged\")\n"
      ],
      "metadata": {
        "id": "VQlC_7luKLjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools in LangGraph\n",
        "\n",
        "LangGraph is a powerful framework that models processes as state graphs, enabling you to build agentic systems with clearly defined states and transitions. Tools in LangGraph are external modules or functions that can be integrated into your agent to extend its capabilities‚Äîsuch as data retrieval, analysis, or interaction‚Äîwithout altering the core graph structure.\n",
        "\n",
        "## How Tools Enhance LangGraph Agents\n",
        "\n",
        "Integrating tools allows your agent to access real-time information or perform complex computations that are outside the scope of the state graph itself. For example, a search tool can fetch up-to-date information from the web, enriching the agent's context and supporting more informed decision-making.\n",
        "\n",
        "## Adding Tavily to This Lab\n",
        "\n",
        "In this lab, we added the Tavily search tool to provide external context when a passenger's luggage is flagged for potential risk. Tavily is used to perform a web search on the flagged items, supplying relevant information‚Äîsuch as recent news or safety alerts‚Äîthat can help the user decide whether to pass or reject the passenger.\n"
      ],
      "metadata": {
        "id": "TWctfNPqOiaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, Annotated\n",
        "from typing import Literal\n",
        "import random\n",
        "import json\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "\n",
        "# ^^^^^ UPDATED: Import Tavily search tool from langchain_community.tools.tavily_search\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# üîë Secure API Keys\n",
        "OPENAI_API_KEY = userdata.get('OpenAI_Key')\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, api_key=OPENAI_API_KEY)\n",
        "\n",
        "# ^^^^^ UPDATED: Initialize Tavily search tool with a maximum of 3 results and pass the API key from userdata.\n",
        "tavily_search_tool = TavilySearchResults(max_results=3, tavily_api_key=userdata.get('Tavily_Key'))\n",
        "\n",
        "# üéØ Define State Schema\n",
        "class AirportState(TypedDict):\n",
        "    passenger_type: str         # \"TSA\" or \"Regular\"\n",
        "    luggage: Annotated[list, \"merge\"]         # Luggage details (set once)\n",
        "    screening_notes: Annotated[list, \"merge\"] # Screening decisions\n",
        "    flagged: bool               # True if extra screening is needed\n",
        "\n",
        "# üèóÔ∏è Initialize Persistent Memory\n",
        "memory_store = {\"total_passengers\": 0, \"flagged_passengers\": 0}\n",
        "\n",
        "def create_passenger(state: AirportState) -> AirportState:\n",
        "    \"\"\"Creates a passenger and assigns luggage.\"\"\"\n",
        "    print(\"üõ´ Passenger enters airport security.\")\n",
        "    if \"luggage\" not in state or not state[\"luggage\"]:\n",
        "        if random.random() < 0.5:\n",
        "            # ^^^^^ UPDATED: Mention dangerous or unusual items in the prompt.\n",
        "            prompt = (\n",
        "                \"List 6-10 items in the passenger's luggage, including 1-2 dangerous or unusual items \"\n",
        "                \"that might require extra screening. Format response as a JSON list. \"\n",
        "                \"(Example: [\\\"Laptop\\\", \\\"Water Bottle\\\", \\\"Unknown Device\\\", \\\"Pocket Knife\\\"])\"\n",
        "            )\n",
        "            print(\"‚ö†Ô∏è Generating luggage with potential dangerous/unusual items...\")\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"List 6-10 common travel items in the passenger's luggage. \"\n",
        "                \"Do NOT include dangerous items. Format response as a JSON list. \"\n",
        "                \"(Example: [\\\"Backpack\\\", \\\"Sunglasses\\\", \\\"Travel Pillow\\\", \\\"Shoes\\\"])\"\n",
        "            )\n",
        "        response = llm([HumanMessage(content=prompt)])\n",
        "        try:\n",
        "            items = json.loads(response.content)\n",
        "            if isinstance(items, list):\n",
        "                state[\"luggage\"] = items\n",
        "            else:\n",
        "                raise ValueError(\"Invalid format received from LLM.\")\n",
        "        except json.JSONDecodeError:\n",
        "            state[\"luggage\"] = [\"Unknown Item\"]\n",
        "    print(f\"üéí Luggage: {state['luggage']}\")\n",
        "    return state\n",
        "\n",
        "def assign_lane(state: AirportState) -> Literal[\"tsa_entry\", \"regular_entry\"]:\n",
        "    if random.random() < 0.3:\n",
        "        print(\"üü¢ Passenger is TSA PreCheck.\")\n",
        "        state[\"passenger_type\"] = \"TSA\"\n",
        "        return \"tsa_entry\"\n",
        "    else:\n",
        "        print(\"üîµ Passenger is Regular Screening.\")\n",
        "        state[\"passenger_type\"] = \"Regular\"\n",
        "        return \"regular_entry\"\n",
        "\n",
        "def tsa_entry(state: AirportState) -> AirportState:\n",
        "    print(\"üü¢ TSA passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_scan(state: AirportState) -> AirportState:\n",
        "    return run_ai_screening(state, \"TSA\")\n",
        "\n",
        "def tsa_decision(state: AirportState) -> Literal[\"tsa_extra\", \"tsa_clear\"]:\n",
        "    return \"tsa_extra\" if state[\"flagged\"] else \"tsa_clear\"\n",
        "\n",
        "def tsa_extra(state: AirportState) -> AirportState:\n",
        "    print(\"‚ö†Ô∏è TSA passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"TSA passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def tsa_clear(state: AirportState) -> AirportState:\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "def regular_entry(state: AirportState) -> AirportState:\n",
        "    print(\"üîé Regular passenger enters screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_scan(state: AirportState) -> AirportState:\n",
        "    return run_ai_screening(state, \"Regular\")\n",
        "\n",
        "def regular_decision(state: AirportState) -> Literal[\"regular_extra\", \"regular_clear\"]:\n",
        "    return \"regular_extra\" if state[\"flagged\"] else \"regular_clear\"\n",
        "\n",
        "def regular_extra(state: AirportState) -> AirportState:\n",
        "    print(\"‚ö†Ô∏è Regular passenger undergoing additional screening.\")\n",
        "    state.setdefault(\"screening_notes\", []).append(\"Regular passenger sent to extra screening.\")\n",
        "    return state\n",
        "\n",
        "def regular_clear(state: AirportState) -> AirportState:\n",
        "    return proceed_to_gates(state)\n",
        "\n",
        "def proceed_to_gates(state: AirportState) -> AirportState:\n",
        "    print(\"‚úÖ Passenger cleared security. Proceeding to gates!\")\n",
        "    return state\n",
        "\n",
        "def run_ai_screening(state: AirportState, passenger_type: str) -> AirportState:\n",
        "    global memory_store\n",
        "    prompt = f\"Luggage: {state['luggage']}. Should this {passenger_type} passenger be flagged? Answer 'Yes' or 'No' with a short reason.\"\n",
        "    response = llm([HumanMessage(content=prompt)])\n",
        "    state[\"flagged\"] = \"yes\" in response.content.lower()\n",
        "    state.setdefault(\"screening_notes\", []).append(response.content)\n",
        "    memory_store[\"total_passengers\"] += 1\n",
        "    if state[\"flagged\"]:\n",
        "        memory_store[\"flagged_passengers\"] += 1\n",
        "\n",
        "        # ^^^^^ UPDATED: LLM provides a 2-3 sentence comment on risks.\n",
        "        comment_prompt = (\n",
        "            f\"Passenger Flagged: Luggage Items: {state['luggage']}. \"\n",
        "            \"Please provide a brief, 2-3 sentence comment that explains the potential risks associated with these items.\"\n",
        "        )\n",
        "        comment_response = llm([HumanMessage(content=comment_prompt)])\n",
        "        state.setdefault(\"screening_notes\", []).append(\"Flagged Comment: \" + comment_response.content)\n",
        "        print(f\"üõÉ LLM Comment on Flagged Passenger: {comment_response.content}\")\n",
        "\n",
        "        # ^^^^^ UPDATED: Call the Tavily search tool to get external information.\n",
        "        search_query = \" \".join(state[\"luggage\"]) + \" dangerous unusual security\"\n",
        "        tavily_result = tavily_search_tool.invoke(search_query)\n",
        "        # ^^^^^ UPDATED: Convert each element to string if needed before joining.\n",
        "        tavily_str = \", \".join([str(item) for item in tavily_result]) if isinstance(tavily_result, list) else str(tavily_result)\n",
        "        state.setdefault(\"screening_notes\", []).append(\"Tavily Search Result: \" + tavily_str)\n",
        "        print(f\"üîç Tavily Search Result: {tavily_str}\")\n",
        "\n",
        "        # ^^^^^ UPDATED: Prompt the user with a text input (Y/N) for decision.\n",
        "        user_input = input(\"Flagged passenger. Enter Y to Pass or N to Reject: \").strip().lower()\n",
        "        while user_input not in ['y', 'n']:\n",
        "            print(\"Invalid input. Please enter Y or N.\")\n",
        "            user_input = input(\"Flagged passenger. Enter Y to Pass or N to Reject: \").strip().lower()\n",
        "        user_decision = \"pass\" if user_input == 'y' else \"reject\"\n",
        "        state.setdefault(\"screening_notes\", []).append(\"User Decision: \" + user_decision)\n",
        "        print(f\"User Decision on flagged passenger: {user_decision}\")\n",
        "\n",
        "    decision = \"‚ö†Ô∏è Extra Screening Required!\" if state[\"flagged\"] else \"‚úÖ Cleared for Gates.\"\n",
        "    print(f\"üõÉ AI Screening Decision: {decision} ({response.content})\")\n",
        "    return state\n",
        "\n",
        "builder = StateGraph(AirportState)\n",
        "builder.add_node(\"create_passenger\", create_passenger)\n",
        "builder.add_node(\"tsa_entry\", tsa_entry)\n",
        "builder.add_node(\"regular_entry\", regular_entry)\n",
        "builder.add_node(\"tsa_scan\", tsa_scan)\n",
        "builder.add_node(\"regular_scan\", regular_scan)\n",
        "builder.add_node(\"tsa_extra\", tsa_extra)\n",
        "builder.add_node(\"regular_extra\", regular_extra)\n",
        "builder.add_node(\"tsa_clear\", tsa_clear)\n",
        "builder.add_node(\"regular_clear\", regular_clear)\n",
        "builder.add_node(\"proceed_to_gates\", proceed_to_gates)\n",
        "builder.add_edge(START, \"create_passenger\")\n",
        "builder.add_conditional_edges(\"create_passenger\", assign_lane)\n",
        "builder.add_edge(\"tsa_entry\", \"tsa_scan\")\n",
        "builder.add_conditional_edges(\"tsa_scan\", tsa_decision)\n",
        "builder.add_edge(\"tsa_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"tsa_clear\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"regular_entry\", \"regular_scan\")\n",
        "builder.add_conditional_edges(\"regular_scan\", regular_decision)\n",
        "builder.add_edge(\"regular_extra\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"regular_clear\", \"proceed_to_gates\")\n",
        "builder.add_edge(\"proceed_to_gates\", END)\n",
        "graph = builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "for _ in range(6):\n",
        "    print(\"\\nüöÄ Processing New Passenger üöÄ\")\n",
        "    graph.invoke({})\n",
        "    print(f\"\\nüìà FINAL STATS: {memory_store['total_passengers']} Total, {memory_store['flagged_passengers']} Flagged\")\n"
      ],
      "metadata": {
        "id": "N0qczbEwz1yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwQ_1k_INfv8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}