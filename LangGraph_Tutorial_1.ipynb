{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfLgckgSCupssP9aNH3tcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdehghani86/AppliedGenAI/blob/main/LangGraph_Tutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangGraph Lab _ Tutorial 1 üöÄ**\n",
        "- Prof. Dehghani\n",
        "## **Building More Controllable LLM Agents with LangGraph**\n",
        "\n",
        "## **Introduction**\n",
        "LangGraph is a framework designed for building **agent and multi-agent applications** with structured control. While large language models (LLMs) are powerful, they often require **more precise workflows** to ensure reliability.\n",
        "\n",
        "Many real-world applications need agents to follow **specific steps**, such as always calling a certain tool first or adjusting their prompts based on the current state. Traditional agent frameworks may not provide enough control for these scenarios. LangGraph introduces a **graph-based approach** that allows developers to define structured workflows while still benefiting from LLM flexibility.\n",
        "\n",
        "This lab is adapted from [LangChain Academy's Intro to LangGraph](https://academy.langchain.com/courses/intro-to-langgraph), which provides additional details and use cases.\n",
        "\n",
        "## **Lab Objectives**\n",
        "By the end of this lab, the following concepts will be covered:\n",
        "- The role of **graphs** in LLM-based agent workflows\n",
        "- How to define **nodes** (decision points) and **edges** (paths) in LangGraph\n",
        "- Implementing an **agent with controlled decision-making**\n",
        "- Exploring **multi-agent interactions** within a structured framework\n",
        "\n",
        "## **Getting Started**\n",
        "Run the following cell to install the required libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "-sCUJNA-pzym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUBqvLcsoxyf"
      },
      "outputs": [],
      "source": [
        "# üöÄ Install necessary libraries for LangGraph-based agent workflows\n",
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python\n",
        "\n",
        "# langchain_openai: Provides integration with OpenAI models\n",
        "# langchain_core: Core components for building LangChain applications\n",
        "# langchain_community: Community-contributed integrations and tools\n",
        "# tavily-python: Enables web search capabilities for retrieval-augmented generation (RAG)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Retrieve OpenAI API key securely from Colab's userdata storage\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OpenAI_Key')  # Fetch the stored API key\n",
        "\n",
        "# Ensure the key is set as an environment variable\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"‚úÖ OpenAI API key successfully set.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è OpenAI API key not found. Please store it using Colab's userdata feature.\")\n"
      ],
      "metadata": {
        "id": "dCcipqIhrJmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Using GPT-4o and GPT-3.5 in LangChain  \n",
        "\n",
        "This section initializes **GPT-4o** and **GPT-3.5 Turbo** models using LangChain.  \n",
        "It demonstrates how to:  \n",
        "- Create a **human message** and send it as part of a conversation.  \n",
        "- Invoke both models with **single text inputs** and **message lists**.  \n",
        "- Print the responses for comparison.  \n",
        "\n",
        "Run the code to see how different models respond to the same input.\n"
      ],
      "metadata": {
        "id": "dfy7PTgGrxEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Initialize OpenAI Chat Models (GPT-4o & GPT-3.5)\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Set up GPT-4o and GPT-3.5 Turbo with zero temperature for deterministic responses\n",
        "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "# üó£Ô∏è Create a human message instance\n",
        "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
        "\n",
        "# Store the message inside a list (models expect message sequences)\n",
        "messages = [msg]\n",
        "\n",
        "#  Invoke the GPT-4o model with a message list\n",
        "response_4o = gpt4o_chat.invoke(messages)\n",
        "\n",
        "#  Invoke the GPT-4o and GPT-3.5 models with a simple text prompt\n",
        "response_4o_text = gpt4o_chat.invoke(\"hello world\")\n",
        "response_35_text = gpt35_chat.invoke(\"hello world\")\n",
        "\n",
        "# ‚úÖ Display responses\n",
        "print(\"GPT-4o Response:\", response_4o)\n",
        "print(\"GPT-4o (Text) Response:\", response_4o_text)\n",
        "print(\"GPT-3.5 Response:\", response_35_text)\n"
      ],
      "metadata": {
        "id": "HJU_ydrxrJ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîé What is Tavily?  \n",
        "\n",
        "[Tavily](https://tavily.com/) is a web search API that allows AI applications to retrieve real-time information from the internet.  \n",
        "It is commonly used in *retrieval-augmented generation (RAG)* systems, where an LLM enhances responses by fetching *up-to-date* and relevant data from external sources.  \n",
        "\n",
        "In this lab, Tavily will be used to perform web searches and integrate real-world information into LangGraph workflows.  \n"
      ],
      "metadata": {
        "id": "TFrC1ADBsQRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Retrieve Tavily API key securely from Colab's userdata storage\n",
        "tavily_api_key = userdata.get('Tavily_Key')  # Fetch the stored API key\n",
        "\n",
        "# Ensure the key is set as an environment variable\n",
        "if tavily_api_key:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
        "    print(\"‚úÖ Tavily API key successfully set.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Tavily API key not found. Please store it using Colab's userdata feature.\")\n"
      ],
      "metadata": {
        "id": "yEHHfRr6rpZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Using Tavily for Web Search in LangChain\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Initialize Tavily search tool with a maximum of 3 results\n",
        "tavily_search = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Perform a web search query\n",
        "query = \"What is LangGraph?\"\n",
        "search_docs = tavily_search.invoke(query)\n",
        "\n",
        "# ‚úÖ Display the retrieved search results\n",
        "print(\"üîπ Tavily Search Results for:\", query)\n",
        "print(search_docs)\n"
      ],
      "metadata": {
        "id": "sNHGFpEisuN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Simplest Graph  \n",
        "\n",
        "Let's build a simple graph with **three nodes** and **one conditional edge**. This structure allows an agent to make a decision at a branching point, directing the flow based on predefined conditions.  \n",
        "\n",
        "<img src=\"https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dba5f465f6e9a2482ad935_simple-graph1.png\" width=\"600\"/>  \n",
        "\n",
        "This example demonstrates how **LangGraph** enables structured decision-making while maintaining flexibility.  \n"
      ],
      "metadata": {
        "id": "iPZfc7FKtqXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LangGraph without displaying unnecessary warnings\n",
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph\n"
      ],
      "metadata": {
        "id": "adMGXAd8s52c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Understanding Graph Components  \n",
        "\n",
        "LangGraph workflows consist of **three main components**: *State, Nodes, and Edges*. Each plays a key role in defining how information flows through the graph.  \n",
        "\n",
        "---\n",
        "\n",
        "## üß† State  \n",
        "\n",
        "The **State** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)) acts as the **shared memory** of the graph, storing data that nodes can read and modify.  \n",
        "\n",
        "- Every *node and edge* interacts with the state.  \n",
        "- It is defined using `TypedDict` from Python‚Äôs `typing` module, which helps structure data with type hints.  \n",
        "- Nodes modify the state by updating specific keys.  \n",
        "\n",
        "---\n",
        "\n",
        "## üîµ Nodes  \n",
        "\n",
        "A **Node** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes)) is a simple **Python function** that processes the state.  \n",
        "\n",
        "- The **first argument** of a node function is always the *state*.  \n",
        "- Nodes can *read and modify* the state using keys like `state['graph_state']`.  \n",
        "- By default, when a node returns a value, it updates the state and replaces the previous value ([reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) handle this).  \n",
        "\n",
        "---\n",
        "\n",
        "## üîÄ Edges  \n",
        "\n",
        "An **Edge** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges)) connects nodes and controls how data moves between them.  \n",
        "\n",
        "Two types of edges exist:  \n",
        "- **Normal Edges** ‚Üí Always transition from one node to the next (e.g., `node_1 ‚Üí node_2`).  \n",
        "- **Conditional Edges** ([docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)) ‚Üí Decide the next node dynamically based on logic.  \n",
        "\n",
        "Conditional edges *act like decision points*, determining the next step in the workflow.  \n"
      ],
      "metadata": {
        "id": "ldOostBhtwUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Literal\n",
        "import random\n",
        "\n",
        "# üéØ Define the State Schema\n",
        "# The state acts as shared memory for the graph.\n",
        "# It stores a key-value pair where 'graph_state' holds a string that evolves as nodes modify it.\n",
        "class State(TypedDict):\n",
        "    graph_state: str  # Tracks the sentence as it builds through the nodes\n",
        "\n",
        "# üîµ Define Nodes\n",
        "# Each node modifies the 'graph_state' by appending its own text.\n",
        "# Nodes simulate a simple sentence-building process.\n",
        "\n",
        "def node_1(state: State) -> State:\n",
        "    \"\"\"Node 1 initializes the sentence with 'I am'.\"\"\"\n",
        "    print(\"--- Node 1 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" I am\"}\n",
        "\n",
        "def node_2(state: State) -> State:\n",
        "    \"\"\"Node 2 completes the sentence with 'happy!'.\"\"\"\n",
        "    print(\"--- Node 2 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" happy!\"}\n",
        "\n",
        "def node_3(state: State) -> State:\n",
        "    \"\"\"Node 3 completes the sentence with 'sad!'.\"\"\"\n",
        "    print(\"--- Node 3 ---\")\n",
        "    return {\"graph_state\": state[\"graph_state\"] + \" sad!\"}\n",
        "\n",
        "# üîÄ Define the Decision Function\n",
        "# This function decides whether to send the state to Node 2 or Node 3.\n",
        "# It randomly picks between the two, simulating an unpredictable emotional outcome.\n",
        "\n",
        "def decide_mood(state: State) -> Literal[\"node_2\", \"node_3\"]:\n",
        "    \"\"\"Randomly selects between Node 2 (happy) and Node 3 (sad).\"\"\"\n",
        "\n",
        "    # Simulate a 50/50 decision\n",
        "    if random.random() < 0.5:\n",
        "        return \"node_2\"  # 50% chance to go to Node 2 (happy)\n",
        "    return \"node_3\"  # 50% chance to go to Node 3 (sad)\n"
      ],
      "metadata": {
        "id": "rSoT9P3NtseJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Graph Construction  \n",
        "\n",
        "Now, it's time to build the graph using the **components** defined earlier. The **StateGraph class** is used to create and manage the graph structure.  \n",
        "\n",
        "### üèóÔ∏è Steps to Build the Graph  \n",
        "1. **Initialize the Graph** ‚Üí Create a `StateGraph` using the `State` class.  \n",
        "2. **Add Nodes and Edges** ‚Üí Define how the graph flows.  \n",
        "3. **Use Special Nodes**:  \n",
        "   - **`START` Node** ‚Üí Sends user input into the graph.  \n",
        "   - **`END` Node** ‚Üí Represents a terminal state.  \n",
        "4. **Compile the Graph** ‚Üí Ensures structural validity.  \n",
        "5. **Visualize** ‚Üí Convert it into a **Mermaid diagram** for better understanding.  \n",
        "\n",
        "### üîó Reference Table  \n",
        "\n",
        "| Concept       | Documentation Link |\n",
        "|--------------|------------------|\n",
        "| StateGraph Class | [StateGraph Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) |\n",
        "| START Node   | [START Node Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) |\n",
        "| END Node     | [END Node Docs](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) |\n",
        "| Graph Compilation | [Compiling a Graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) |\n",
        "| Mermaid Diagrams | [Mermaid Docs](https://github.com/mermaid-js/mermaid) |\n",
        "\n",
        "This approach makes the graph more **structured, adaptable, and easy to debug**.  \n"
      ],
      "metadata": {
        "id": "lrjO8J8DvENy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# üèóÔ∏è Initialize the Graph Builder\n",
        "# The StateGraph is created using the State schema defined earlier.\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# üîµ Add Nodes\n",
        "# Each node represents a step in the process and modifies the graph_state.\n",
        "builder.add_node(\"node_1\", node_1)  # Starts the sentence\n",
        "builder.add_node(\"node_2\", node_2)  # Appends \"happy!\"\n",
        "builder.add_node(\"node_3\", node_3)  # Appends \"sad!\"\n",
        "\n",
        "# üîó Define Graph Flow (Edges)\n",
        "# Edges define how nodes connect to each other.\n",
        "\n",
        "# The START node sends input to \"node_1\"\n",
        "builder.add_edge(START, \"node_1\")\n",
        "\n",
        "# From \"node_1\", the next step is decided dynamically using the decide_mood function.\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "\n",
        "# \"node_2\" (happy) and \"node_3\" (sad) both lead to the END node.\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# ‚úÖ Compile the Graph\n",
        "# This ensures that the structure is valid and ready for execution.\n",
        "graph = builder.compile()\n",
        "\n",
        "# üñºÔ∏è Visualize the Graph\n",
        "# Generates a Mermaid diagram to display the flow of nodes and edges.\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "id": "OskefMiJvDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Invocation  \n",
        "\n",
        "The compiled graph follows the [runnable](https://python.langchain.com/docs/concepts/runnables/) protocol, providing a standardized way to execute LangChain components. The `invoke` method is used to start execution, with an input dictionary like `{\"graph_state\": \"Hi, this is Lance.\"}` setting the initial state. The graph begins at the `START` node and moves through the defined nodes (`node_1`, `node_2`, `node_3`) based on the control flow. A conditional edge determines whether the execution moves from `node_1` to `node_2` or `node_3`, following a 50/50 probability rule. Each node processes the current state, modifies the `graph_state` value, and returns the updated state. The execution continues along the directed edges until it reaches the `END` node, where the final graph state is returned.\n"
      ],
      "metadata": {
        "id": "c9PlWY6jvvf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
      ],
      "metadata": {
        "id": "1tEzUm9QveUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîó Chain  \n",
        "\n",
        "A simple graph has been built using **nodes**, **normal edges**, and **conditional edges** to control execution flow.  \n",
        "\n",
        "## üéØ Goals  \n",
        "\n",
        "The next step is to construct a **chain** that integrates key LangChain concepts. This involves:  \n",
        "\n",
        "- Using **chat messages** as the graph state.  \n",
        "- Incorporating **chat models** within graph nodes.  \n",
        "- Binding tools to enhance the chat model's functionality.  \n",
        "- Executing tool calls within graph nodes for dynamic interactions.  \n",
        "\n",
        "## üîó Reference Table  \n",
        "\n",
        "| Concept            | Documentation Link |\n",
        "|--------------------|------------------|\n",
        "| Chat Messages     | [Chat Messages](https://python.langchain.com/v0.2/docs/concepts/#messages) |\n",
        "| Chat Models       | [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) |\n",
        "| Binding Tools     | [Binding Tools](https://python.langchain.com/v0.2/docs/concepts/#tools) |\n",
        "| Executing Tool Calls | [Tool Calling](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) |\n",
        "\n",
        "## üìå Chain Structure  \n",
        "\n",
        "<img src=\"https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png\" width=\"600\"/>  \n"
      ],
      "metadata": {
        "id": "O11B-y3fv-ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langgraph"
      ],
      "metadata": {
        "id": "gyRdXjBZvs-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Step 1: Create a conversation flow using AI and Human messages\n",
        "# These messages simulate an interaction between a user (Lance) and an AI model\n",
        "messages = [\n",
        "    AIMessage(content=\"So you said you were researching ocean mammals?\", name=\"Model\"),\n",
        "    HumanMessage(content=\"Yes, that's right.\", name=\"Lance\"),\n",
        "    AIMessage(content=\"Great, what would you like to learn about?\", name=\"Model\"),\n",
        "    HumanMessage(content=\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"),\n",
        "]\n",
        "\n",
        "# Step 2: Print the conversation in a structured format\n",
        "for m in messages:\n",
        "    m.pretty_print()\n",
        "\n",
        "# Step 3: Initialize the graph structure\n",
        "# This graph will control the decision-making process of the AI\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# Step 4: Add nodes to the graph\n",
        "# Each node represents a different processing step\n",
        "builder.add_node(\"node_1\", node_1)  # The first step of processing\n",
        "builder.add_node(\"node_2\", node_2)  # A possible path: AI responds with \"happy!\"\n",
        "builder.add_node(\"node_3\", node_3)  # Another path: AI responds with \"sad!\"\n",
        "\n",
        "# Step 5: Define edges (connections) between nodes\n",
        "# The graph starts at \"node_1\"\n",
        "builder.add_edge(START, \"node_1\")\n",
        "\n",
        "# Step 6: Introduce a conditional decision\n",
        "# The path from \"node_1\" to either \"node_2\" or \"node_3\" is determined randomly\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "\n",
        "# Step 7: Define the ending condition\n",
        "# Both \"node_2\" and \"node_3\" lead to the END node, concluding the process\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# Step 8: Compile the graph\n",
        "# This ensures that all nodes and edges are correctly linked\n",
        "graph = builder.compile()\n",
        "\n",
        "# Step 9: Visualize the graph\n",
        "# Generates a diagram to show how the nodes and edges are connected\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "id": "IWWF4DMfxKUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîó Understanding the Chat-Based Chain  \n",
        "\n",
        "This code builds a **chat-driven decision graph** using LangGraph. It begins by simulating a conversation between a user (\"Lance\") and an AI assistant (\"Model\") using chat messages. These messages serve as the **initial state** of the graph. The graph structure is then defined, starting with `node_1`, which processes the input. A **conditional edge** determines whether the response follows a **\"happy\"** or **\"sad\"** path, leading to `node_2` or `node_3` respectively. The decision is made randomly using the `decide_mood` function. Finally, the graph is compiled and visualized, showing the flow of decisions and responses in a structured manner.\n"
      ],
      "metadata": {
        "id": "tHYBuPNNxkF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Understanding the Code: Tool-Enhanced ChatGPT with LangGraph  \n",
        "\n",
        "### üîó **Binding a Tool to the LLM**  \n",
        "This code integrates a **structured tool (`multiply`)** with an LLM using **LangChain and LangGraph**. The `multiply` function is registered as a tool and bound to the **ChatGPT model (`gpt-3.5-turbo`)**. When the user asks a mathematical question like *\"What is 2 multiplied by 3?\"*, the LLM **extracts the numbers** and generates a structured tool call. This tool call outputs a **payload** (e.g., `{\"a\":2, \"b\":3}`), which is then processed by the tool to return `6`.  \n",
        "\n",
        "### üì© **Using a Message-Based State**  \n",
        "The state in this implementation is managed using **message history (`MessagesState`)**, where interactions between the AI and user are stored as a list of messages. The **`add_messages` reducer** ensures that every new message is appended to the conversation state, allowing the LLM to retain context. This is demonstrated by adding a new message to an existing conversation and verifying that the updated state includes all past interactions.  \n",
        "\n",
        "### üîÑ **Building and Running the LangGraph Workflow**  \n",
        "A **LangGraph workflow** is created where:  \n",
        "1. The conversation state is passed to the **tool-enhanced LLM** (`tool_calling_llm` node).  \n",
        "2. The LLM **decides whether to use a tool** or respond directly based on the input.  \n",
        "3. The processed response is returned as the updated message state.  \n",
        "4. The **graph is visualized** using a Mermaid diagram, displaying the flow between nodes.  \n",
        "\n",
        "Finally, two test cases are executed:  \n",
        "- **General query:** The LLM responds conversationally.  \n",
        "- **Tool-based query:** The LLM detects a multiplication request, generates a tool call, and returns the computed result.  \n",
        "\n",
        "This approach demonstrates **structured decision-making** in LLM workflows, where the model can **choose between answering naturally or calling an external function** based on the user's intent.\n"
      ],
      "metadata": {
        "id": "p8ospn9j9U1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "from typing import Dict\n",
        "from langchain_core.messages import AnyMessage, AIMessage, HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# üèóÔ∏è Define a Structured Tool\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers and return the result.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# üß† Initialize the ChatGPT Model with Tool Binding\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools([multiply])  # Bind the multiply function as a tool\n",
        "\n",
        "# üîç Test a Tool Call\n",
        "tool_call = llm_with_tools.invoke([HumanMessage(content=\"What is 2 multiplied by 3?\", name=\"Lance\")])\n",
        "print(\"Tool Call Output:\", tool_call.tool_calls)  # Expected Output: {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
        "\n",
        "# üì© Define a State to Store Messages\n",
        "class MessagesState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]  # Uses add_messages reducer to append messages\n",
        "\n",
        "# üìå Test the Reducer: Appending Messages\n",
        "initial_messages = [\n",
        "    AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
        "    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
        "]\n",
        "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
        "\n",
        "# ‚úÖ Test the `add_messages` reducer\n",
        "updated_messages = add_messages(initial_messages, new_message)\n",
        "print(\"Updated Messages:\", updated_messages)\n",
        "\n",
        "# üîß Define a Node for Tool-Calling LLM\n",
        "def tool_calling_llm(state: MessagesState):\n",
        "    \"\"\"Passes the conversation state to the LLM with tool capabilities.\"\"\"\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# üèóÔ∏è Build the Graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_edge(\"tool_calling_llm\", END)\n",
        "graph = builder.compile()\n",
        "\n",
        "# üìä Visualize the Graph\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# üìù Example 1: Invoke LLM without tool usage (General Query)\n",
        "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()\n",
        "\n",
        "# üìù Example 2: Invoke LLM with tool usage (Math Calculation)\n",
        "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()\n"
      ],
      "metadata": {
        "id": "bCzqCYVPxLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4mqvuJ-x82V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}