{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cajtKcbOjCtC"
      },
      "source": [
        "# Intro to Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2SEAXPjjCtH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm1_ztJjjCtI"
      },
      "outputs": [],
      "source": [
        "\n",
        "x = int(input())\n",
        "np.random.randn(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9dUokwQjCtI"
      },
      "source": [
        "*This is Markdown text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU-3s4fPjCtI"
      },
      "source": [
        "## Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipoTrowXjCtI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL2Gx9O7jCtJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtdJYuxqjCtJ"
      },
      "source": [
        "## Pulling a Notebook from GitHub\n",
        "\n",
        "[https://github.com/mdehghani86/AppliedGenAI](https://github.com/mdehghani86/AppliedGenAI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2xLmwuRjCtJ"
      },
      "source": [
        "## Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJzfS4KDjCtJ"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\" # Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH9TVCLQjCtJ"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwo_d7NbjCtJ"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSnXmudTjCtJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9eoNnZsjCtK"
      },
      "source": [
        "## Run your first prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_da8Y53jCtK"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaMxJ93cjCtK"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Your Question here\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr8MTrDFjCtK"
      },
      "source": [
        "Continue the conversation with History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfSd8vT2jCtK"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Follow up question\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_NChZZkjCtK"
      },
      "source": [
        "## Tuning parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l86QbKcjCtK"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(\n",
        "        max_output_tokens=2000,\n",
        "        temperature=0.9,\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahAhhxbSjCtK"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    'List out <your prompt here>',\n",
        "    # Limit to 3 points\n",
        "    generation_config = genai.GenerationConfig(stop_sequences=['\\n4'])\n",
        ")\n",
        "print(response.text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}